{
  "commit": "2e789f7",
  "parent": "6d7a9d2aba140e1c3948111299f064c3500cfac6",
  "repo": "D:\\locbench\\loguru",
  "num_files_in_diff": 3,
  "num_py_files_in_diff": 3,
  "num_seeds": 50,
  "seeds": [
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 6,
      "kind": "class",
      "qualname": "loguru._recattrs.RecordLevel",
      "span": [
        5,
        48
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class RecordLevel:\n    \"\"\"A class representing the logging level record with name, number and icon.\n\n    Attributes\n    ----------\n        icon (str): The icon representing the log level\n        name (str): The name of the log level\n        no (int): The numeric value of the log level\n    \"\"\"\n\n    __slots__ = (\"icon\", \"name\", \"no\")\n\n    def __init__(self, name, no, icon):\n        \"\"\"Initialize a RecordLevel instance.\n\n        Args:\n            name (str): The name of the log level\n            no (int): The numeric value of the log level\n            icon (str): The icon representing the log level\n        \"\"\"\n        self.name = name\n        self.no = no\n        self.icon = icon\n\n    def __repr__(self):\n        \"\"\"Return string representation of RecordLevel.\n\n        Returns\n        -------\n            str: Formatted string with name, number and icon\n        \"\"\"\n        return \"(name=%r, no=%r, icon=%r)\" % (self.name, self.no, self.icon)\n\n    def __format__(self, spec):\n        \"\"\"Format the RecordLevel instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted name according to specification\n        \"\"\"\n        return self.name.__format__(spec)",
      "old_code": "class RecordLevel:\n    __slots__ = (\"icon\", \"name\", \"no\")\n\n    def __init__(self, name, no, icon):\n        self.name = name\n        self.no = no\n        self.icon = icon\n\n    def __repr__(self):\n        return \"(name=%r, no=%r, icon=%r)\" % (self.name, self.no, self.icon)\n\n    def __format__(self, spec):\n        return self.name.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 18,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordLevel.__init__",
      "span": [
        17,
        27
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, name, no, icon):\n        \"\"\"Initialize a RecordLevel instance.\n\n        Args:\n            name (str): The name of the log level\n            no (int): The numeric value of the log level\n            icon (str): The icon representing the log level\n        \"\"\"\n        self.name = name\n        self.no = no\n        self.icon = icon",
      "old_code": "    def __init__(self, name, no, icon):\n        self.name = name\n        self.no = no\n        self.icon = icon"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 30,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordLevel.__repr__",
      "span": [
        29,
        36
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __repr__(self):\n        \"\"\"Return string representation of RecordLevel.\n\n        Returns\n        -------\n            str: Formatted string with name, number and icon\n        \"\"\"\n        return \"(name=%r, no=%r, icon=%r)\" % (self.name, self.no, self.icon)",
      "old_code": "    def __repr__(self):\n        return \"(name=%r, no=%r, icon=%r)\" % (self.name, self.no, self.icon)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 39,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordLevel.__format__",
      "span": [
        38,
        48
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __format__(self, spec):\n        \"\"\"Format the RecordLevel instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted name according to specification\n        \"\"\"\n        return self.name.__format__(spec)",
      "old_code": "    def __format__(self, spec):\n        return self.name.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 52,
      "kind": "class",
      "qualname": "loguru._recattrs.RecordFile",
      "span": [
        51,
        91
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class RecordFile:\n    \"\"\"A class representing a file record with name and path.\n\n    Attributes\n    ----------\n        name (str): The name of the file\n        path (str): The path to the file\n    \"\"\"\n\n    __slots__ = (\"name\", \"path\")\n\n    def __init__(self, name, path):\n        \"\"\"Initialize a RecordFile instance.\n\n        Args:\n            name (str): The name of the file\n            path (str): The path to the file\n        \"\"\"\n        self.name = name\n        self.path = path\n\n    def __repr__(self):\n        \"\"\"Return string representation of RecordFile.\n\n        Returns\n        -------\n            str: Formatted string with name and path\n        \"\"\"\n        return \"(name=%r, path=%r)\" % (self.name, self.path)\n\n    def __format__(self, spec):\n        \"\"\"Format the RecordFile instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted name according to specification\n        \"\"\"\n        return self.name.__format__(spec)",
      "old_code": "class RecordFile:\n    __slots__ = (\"name\", \"path\")\n\n    def __init__(self, name, path):\n        self.name = name\n        self.path = path\n\n    def __repr__(self):\n        return \"(name=%r, path=%r)\" % (self.name, self.path)\n\n    def __format__(self, spec):\n        return self.name.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 63,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordFile.__init__",
      "span": [
        62,
        70
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, name, path):\n        \"\"\"Initialize a RecordFile instance.\n\n        Args:\n            name (str): The name of the file\n            path (str): The path to the file\n        \"\"\"\n        self.name = name\n        self.path = path",
      "old_code": "    def __init__(self, name, path):\n        self.name = name\n        self.path = path"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 73,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordFile.__repr__",
      "span": [
        72,
        79
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __repr__(self):\n        \"\"\"Return string representation of RecordFile.\n\n        Returns\n        -------\n            str: Formatted string with name and path\n        \"\"\"\n        return \"(name=%r, path=%r)\" % (self.name, self.path)",
      "old_code": "    def __repr__(self):\n        return \"(name=%r, path=%r)\" % (self.name, self.path)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 82,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordFile.__format__",
      "span": [
        81,
        91
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __format__(self, spec):\n        \"\"\"Format the RecordFile instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted name according to specification\n        \"\"\"\n        return self.name.__format__(spec)",
      "old_code": "    def __format__(self, spec):\n        return self.name.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 95,
      "kind": "class",
      "qualname": "loguru._recattrs.RecordThread",
      "span": [
        94,
        134
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class RecordThread:\n    \"\"\"A class representing a thread record with ID and name.\n\n    Attributes\n    ----------\n        id (int): The thread ID\n        name (str): The thread name\n    \"\"\"\n\n    __slots__ = (\"id\", \"name\")\n\n    def __init__(self, id_, name):\n        \"\"\"Initialize a RecordThread instance.\n\n        Args:\n            id_ (int): The thread ID\n            name (str): The thread name\n        \"\"\"\n        self.id = id_\n        self.name = name\n\n    def __repr__(self):\n        \"\"\"Return string representation of RecordThread.\n\n        Returns\n        -------\n            str: Formatted string with id and name\n        \"\"\"\n        return \"(id=%r, name=%r)\" % (self.id, self.name)\n\n    def __format__(self, spec):\n        \"\"\"Format the RecordThread instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted ID according to specification\n        \"\"\"\n        return self.id.__format__(spec)",
      "old_code": "class RecordThread:\n    __slots__ = (\"id\", \"name\")\n\n    def __init__(self, id_, name):\n        self.id = id_\n        self.name = name\n\n    def __repr__(self):\n        return \"(id=%r, name=%r)\" % (self.id, self.name)\n\n    def __format__(self, spec):\n        return self.id.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 106,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordThread.__init__",
      "span": [
        105,
        113
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, id_, name):\n        \"\"\"Initialize a RecordThread instance.\n\n        Args:\n            id_ (int): The thread ID\n            name (str): The thread name\n        \"\"\"\n        self.id = id_\n        self.name = name",
      "old_code": "    def __init__(self, id_, name):\n        self.id = id_\n        self.name = name"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 116,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordThread.__repr__",
      "span": [
        115,
        122
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __repr__(self):\n        \"\"\"Return string representation of RecordThread.\n\n        Returns\n        -------\n            str: Formatted string with id and name\n        \"\"\"\n        return \"(id=%r, name=%r)\" % (self.id, self.name)",
      "old_code": "    def __repr__(self):\n        return \"(id=%r, name=%r)\" % (self.id, self.name)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 125,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordThread.__format__",
      "span": [
        124,
        134
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __format__(self, spec):\n        \"\"\"Format the RecordThread instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted ID according to specification\n        \"\"\"\n        return self.id.__format__(spec)",
      "old_code": "    def __format__(self, spec):\n        return self.id.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 138,
      "kind": "class",
      "qualname": "loguru._recattrs.RecordProcess",
      "span": [
        137,
        177
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class RecordProcess:\n    \"\"\"A class representing a process record with ID and name.\n\n    Attributes\n    ----------\n        id (int): The process ID\n        name (str): The process name\n    \"\"\"\n\n    __slots__ = (\"id\", \"name\")\n\n    def __init__(self, id_, name):\n        \"\"\"Initialize a RecordProcess instance.\n\n        Args:\n            id_ (int): The process ID\n            name (str): The process name\n        \"\"\"\n        self.id = id_\n        self.name = name\n\n    def __repr__(self):\n        \"\"\"Return string representation of RecordProcess.\n\n        Returns\n        -------\n            str: Formatted string with id and name\n        \"\"\"\n        return \"(id=%r, name=%r)\" % (self.id, self.name)\n\n    def __format__(self, spec):\n        \"\"\"Format the RecordProcess instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted ID according to specification\n        \"\"\"\n        return self.id.__format__(spec)",
      "old_code": "class RecordProcess:\n    __slots__ = (\"id\", \"name\")\n\n    def __init__(self, id_, name):\n        self.id = id_\n        self.name = name\n\n    def __repr__(self):\n        return \"(id=%r, name=%r)\" % (self.id, self.name)\n\n    def __format__(self, spec):\n        return self.id.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 149,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordProcess.__init__",
      "span": [
        148,
        156
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, id_, name):\n        \"\"\"Initialize a RecordProcess instance.\n\n        Args:\n            id_ (int): The process ID\n            name (str): The process name\n        \"\"\"\n        self.id = id_\n        self.name = name",
      "old_code": "    def __init__(self, id_, name):\n        self.id = id_\n        self.name = name"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 159,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordProcess.__repr__",
      "span": [
        158,
        165
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __repr__(self):\n        \"\"\"Return string representation of RecordProcess.\n\n        Returns\n        -------\n            str: Formatted string with id and name\n        \"\"\"\n        return \"(id=%r, name=%r)\" % (self.id, self.name)",
      "old_code": "    def __repr__(self):\n        return \"(id=%r, name=%r)\" % (self.id, self.name)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 168,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordProcess.__format__",
      "span": [
        167,
        177
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __format__(self, spec):\n        \"\"\"Format the RecordProcess instance.\n\n        Args:\n            spec (str): Format specification\n\n        Returns\n        -------\n            str: Formatted ID according to specification\n        \"\"\"\n        return self.id.__format__(spec)",
      "old_code": "    def __format__(self, spec):\n        return self.id.__format__(spec)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 183,
      "kind": "class",
      "qualname": "loguru._recattrs.RecordException",
      "span": [
        180,
        245
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class RecordException(\n    namedtuple(\"RecordException\", (\"type\", \"value\", \"traceback\"))  # noqa: PYI024\n):\n    \"\"\"A class representing an exception record with type, value and traceback.\n\n    Attributes\n    ----------\n        type: The exception type\n        value: The exception value\n        traceback: The exception traceback\n    \"\"\"\n\n    def __repr__(self):\n        \"\"\"Return string representation of RecordException.\n\n        Returns\n        -------\n            str: Formatted string with type, value and traceback\n        \"\"\"\n        return \"(type=%r, value=%r, traceback=%r)\" % (self.type, self.value, self.traceback)\n\n    def __reduce__(self):\n        \"\"\"Reduce the RecordException for pickling.\n\n        This method handles pickling of the exception, managing cases where\n        the exception value or traceback might not be picklable.\n\n        Returns\n        -------\n            tuple: A tuple containing class and initialization arguments\n        \"\"\"\n        # The traceback is not picklable, therefore it needs to be removed. Additionally, there's a\n        # possibility that the exception value is not picklable either. In such cases, we also need\n        # to remove it. This is done for user convenience, aiming to prevent error logging caused by\n        # custom exceptions from third-party libraries. If the serialization succeeds, we can reuse\n        # the pickled value later for optimization (so that it's not pickled twice). It's important\n        # to note that custom exceptions might not necessarily raise a PickleError, hence the\n        # generic Exception catch.\n        try:\n            pickled_value = pickle.dumps(self.value)\n        except Exception:\n            return (RecordException, (self.type, None, None))\n        else:\n            return (RecordException._from_pickled_value, (self.type, pickled_value, None))\n\n    @classmethod\n    def _from_pickled_value(cls, type_, pickled_value, traceback_):\n        \"\"\"Create a RecordException instance from a pickled value.\n\n        Args:\n            type_: The exception type\n            pickled_value: The pickled exception value\n            traceback_: The exception traceback\n\n        Returns\n        -------\n            RecordException: A new instance with unpickled value\n        \"\"\"\n        try:\n            # It's safe to use \"pickle.loads()\" in this case because the pickled value is generated\n            # by the same code and is not coming from an untrusted source.\n            value = pickle.loads(pickled_value)\n        except Exception:\n            return cls(type_, None, traceback_)\n        else:\n            return cls(type_, value, traceback_)",
      "old_code": "class RecordException(\n    namedtuple(\"RecordException\", (\"type\", \"value\", \"traceback\"))  # noqa: PYI024\n):\n    def __repr__(self):\n        return \"(type=%r, value=%r, traceback=%r)\" % (self.type, self.value, self.traceback)\n\n    def __reduce__(self):\n        # The traceback is not picklable, therefore it needs to be removed. Additionally, there's a\n        # possibility that the exception value is not picklable either. In such cases, we also need\n        # to remove it. This is done for user convenience, aiming to prevent error logging caused by\n        # custom exceptions from third-party libraries. If the serialization succeeds, we can reuse\n        # the pickled value later for optimization (so that it's not pickled twice). It's important\n        # to note that custom exceptions might not necessarily raise a PickleError, hence the\n        # generic Exception catch.\n        try:\n            pickled_value = pickle.dumps(self.value)\n        except Exception:\n            return (RecordException, (self.type, None, None))\n        else:\n            return (RecordException._from_pickled_value, (self.type, pickled_value, None))\n\n    @classmethod\n    def _from_pickled_value(cls, type_, pickled_value, traceback_):\n        try:\n            # It's safe to use \"pickle.loads()\" in this case because the pickled value is generated\n            # by the same code and is not coming from an untrusted source.\n            value = pickle.loads(pickled_value)\n        except Exception:\n            return cls(type_, None, traceback_)\n        else:\n            return cls(type_, value, traceback_)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 193,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordException.__repr__",
      "span": [
        192,
        199
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __repr__(self):\n        \"\"\"Return string representation of RecordException.\n\n        Returns\n        -------\n            str: Formatted string with type, value and traceback\n        \"\"\"\n        return \"(type=%r, value=%r, traceback=%r)\" % (self.type, self.value, self.traceback)",
      "old_code": "    def __repr__(self):\n        return \"(type=%r, value=%r, traceback=%r)\" % (self.type, self.value, self.traceback)"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 202,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordException.__reduce__",
      "span": [
        201,
        223
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __reduce__(self):\n        \"\"\"Reduce the RecordException for pickling.\n\n        This method handles pickling of the exception, managing cases where\n        the exception value or traceback might not be picklable.\n\n        Returns\n        -------\n            tuple: A tuple containing class and initialization arguments\n        \"\"\"\n        # The traceback is not picklable, therefore it needs to be removed. Additionally, there's a\n        # possibility that the exception value is not picklable either. In such cases, we also need\n        # to remove it. This is done for user convenience, aiming to prevent error logging caused by\n        # custom exceptions from third-party libraries. If the serialization succeeds, we can reuse\n        # the pickled value later for optimization (so that it's not pickled twice). It's important\n        # to note that custom exceptions might not necessarily raise a PickleError, hence the\n        # generic Exception catch.\n        try:\n            pickled_value = pickle.dumps(self.value)\n        except Exception:\n            return (RecordException, (self.type, None, None))\n        else:\n            return (RecordException._from_pickled_value, (self.type, pickled_value, None))",
      "old_code": "    def __reduce__(self):\n        # The traceback is not picklable, therefore it needs to be removed. Additionally, there's a\n        # possibility that the exception value is not picklable either. In such cases, we also need\n        # to remove it. This is done for user convenience, aiming to prevent error logging caused by\n        # custom exceptions from third-party libraries. If the serialization succeeds, we can reuse\n        # the pickled value later for optimization (so that it's not pickled twice). It's important\n        # to note that custom exceptions might not necessarily raise a PickleError, hence the\n        # generic Exception catch.\n        try:\n            pickled_value = pickle.dumps(self.value)\n        except Exception:\n            return (RecordException, (self.type, None, None))\n        else:\n            return (RecordException._from_pickled_value, (self.type, pickled_value, None))"
    },
    {
      "path": "loguru/_recattrs.py",
      "version": "new",
      "line": 227,
      "kind": "function",
      "qualname": "loguru._recattrs.RecordException._from_pickled_value",
      "span": [
        226,
        245
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def _from_pickled_value(cls, type_, pickled_value, traceback_):\n        \"\"\"Create a RecordException instance from a pickled value.\n\n        Args:\n            type_: The exception type\n            pickled_value: The pickled exception value\n            traceback_: The exception traceback\n\n        Returns\n        -------\n            RecordException: A new instance with unpickled value\n        \"\"\"\n        try:\n            # It's safe to use \"pickle.loads()\" in this case because the pickled value is generated\n            # by the same code and is not coming from an untrusted source.\n            value = pickle.loads(pickled_value)\n        except Exception:\n            return cls(type_, None, traceback_)\n        else:\n            return cls(type_, value, traceback_)",
      "old_code": "    def _from_pickled_value(cls, type_, pickled_value, traceback_):\n        try:\n            # It's safe to use \"pickle.loads()\" in this case because the pickled value is generated\n            # by the same code and is not coming from an untrusted source.\n            value = pickle.loads(pickled_value)\n        except Exception:\n            return cls(type_, None, traceback_)\n        else:\n            return cls(type_, value, traceback_)"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 9,
      "kind": "class",
      "qualname": "loguru._simple_sinks.StreamSink",
      "span": [
        8,
        45
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class StreamSink:\n    \"\"\"A sink that writes log messages to a stream object.\n\n    Args:\n        stream: A stream object that supports write operations.\n    \"\"\"\n\n    def __init__(self, stream):\n        self._stream = stream\n        self._flushable = callable(getattr(stream, \"flush\", None))\n        self._stoppable = callable(getattr(stream, \"stop\", None))\n        self._completable = inspect.iscoroutinefunction(getattr(stream, \"complete\", None))\n\n    def write(self, message):\n        \"\"\"Write a message to the stream.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        self._stream.write(message)\n        if self._flushable:\n            self._stream.flush()\n\n    def stop(self):\n        \"\"\"Stop the stream if it supports the stop operation.\"\"\"\n        if self._stoppable:\n            self._stream.stop()\n\n    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: List of tasks to complete.\n        \"\"\"\n        if not self._completable:\n            return []\n        return [self._stream.complete()]",
      "old_code": "class StreamSink:\n    def __init__(self, stream):\n        self._stream = stream\n        self._flushable = callable(getattr(stream, \"flush\", None))\n        self._stoppable = callable(getattr(stream, \"stop\", None))\n        self._completable = inspect.iscoroutinefunction(getattr(stream, \"complete\", None))\n\n    def write(self, message):\n        self._stream.write(message)\n        if self._flushable:\n            self._stream.flush()\n\n    def stop(self):\n        if self._stoppable:\n            self._stream.stop()\n\n    def tasks_to_complete(self):\n        if not self._completable:\n            return []\n        return [self._stream.complete()]"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 22,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StreamSink.write",
      "span": [
        21,
        29
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def write(self, message):\n        \"\"\"Write a message to the stream.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        self._stream.write(message)\n        if self._flushable:\n            self._stream.flush()",
      "old_code": "    def write(self, message):\n        self._stream.write(message)\n        if self._flushable:\n            self._stream.flush()"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 32,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StreamSink.stop",
      "span": [
        31,
        34
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def stop(self):\n        \"\"\"Stop the stream if it supports the stop operation.\"\"\"\n        if self._stoppable:\n            self._stream.stop()",
      "old_code": "    def stop(self):\n        if self._stoppable:\n            self._stream.stop()"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 37,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StreamSink.tasks_to_complete",
      "span": [
        36,
        45
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: List of tasks to complete.\n        \"\"\"\n        if not self._completable:\n            return []\n        return [self._stream.complete()]",
      "old_code": "    def tasks_to_complete(self):\n        if not self._completable:\n            return []\n        return [self._stream.complete()]"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 49,
      "kind": "class",
      "qualname": "loguru._simple_sinks.StandardSink",
      "span": [
        48,
        101
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class StandardSink:\n    \"\"\"A sink that writes log messages using the standard logging module.\n\n    Args:\n        handler: A logging handler instance.\n    \"\"\"\n\n    def __init__(self, handler):\n        self._handler = handler\n\n    def write(self, message):\n        \"\"\"Write a message using the standard logging handler.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        raw_record = message.record\n        message = str(message)\n        exc = raw_record[\"exception\"]\n        record = logging.getLogger().makeRecord(\n            raw_record[\"name\"],\n            raw_record[\"level\"].no,\n            raw_record[\"file\"].path,\n            raw_record[\"line\"],\n            message,\n            (),\n            (exc.type, exc.value, exc.traceback) if exc else None,\n            raw_record[\"function\"],\n            {\"extra\": raw_record[\"extra\"]},\n        )\n\n        # By default, the standard logging module will format the exception and assign it to the\n        # \"exc_text\" attribute. Then, the formatted exception will be automatically appended to the\n        # message when the record is formatted. This is a problem, because that would cause the\n        # exception to be duplicated in the log message, since it's also formatted by Loguru. To\n        # avoid this, we set \"exc_text\" to a simple newline character, which will end the message.\n        if exc:\n            record.exc_text = \"\\n\"\n\n        record.levelname = raw_record[\"level\"].name\n        self._handler.handle(record)\n\n    def stop(self):\n        \"\"\"Close the logging handler.\"\"\"\n        self._handler.close()\n\n    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: Empty list as standard sink has no async tasks.\n        \"\"\"\n        return []",
      "old_code": "class StandardSink:\n    def __init__(self, handler):\n        self._handler = handler\n\n    def write(self, message):\n        raw_record = message.record\n        message = str(message)\n        exc = raw_record[\"exception\"]\n        record = logging.getLogger().makeRecord(\n            raw_record[\"name\"],\n            raw_record[\"level\"].no,\n            raw_record[\"file\"].path,\n            raw_record[\"line\"],\n            message,\n            (),\n            (exc.type, exc.value, exc.traceback) if exc else None,\n            raw_record[\"function\"],\n            {\"extra\": raw_record[\"extra\"]},\n        )\n\n        # By default, the standard logging module will format the exception and assign it to the\n        # \"exc_text\" attribute. Then, the formatted exception will be automatically appended to the\n        # message when the record is formatted. This is a problem, because that would cause the\n        # exception to be duplicated in the log message, since it's also formatted by Loguru. To\n        # avoid this, we set \"exc_text\" to a simple newline character, which will end the message.\n        if exc:\n            record.exc_text = \"\\n\"\n\n        record.levelname = raw_record[\"level\"].name\n        self._handler.handle(record)\n\n    def stop(self):\n        self._handler.close()\n\n    def tasks_to_complete(self):\n        return []"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 59,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StandardSink.write",
      "span": [
        58,
        88
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def write(self, message):\n        \"\"\"Write a message using the standard logging handler.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        raw_record = message.record\n        message = str(message)\n        exc = raw_record[\"exception\"]\n        record = logging.getLogger().makeRecord(\n            raw_record[\"name\"],\n            raw_record[\"level\"].no,\n            raw_record[\"file\"].path,\n            raw_record[\"line\"],\n            message,\n            (),\n            (exc.type, exc.value, exc.traceback) if exc else None,\n            raw_record[\"function\"],\n            {\"extra\": raw_record[\"extra\"]},\n        )\n\n        # By default, the standard logging module will format the exception and assign it to the\n        # \"exc_text\" attribute. Then, the formatted exception will be automatically appended to the\n        # message when the record is formatted. This is a problem, because that would cause the\n        # exception to be duplicated in the log message, since it's also formatted by Loguru. To\n        # avoid this, we set \"exc_text\" to a simple newline character, which will end the message.\n        if exc:\n            record.exc_text = \"\\n\"\n\n        record.levelname = raw_record[\"level\"].name\n        self._handler.handle(record)",
      "old_code": "    def write(self, message):\n        raw_record = message.record\n        message = str(message)\n        exc = raw_record[\"exception\"]\n        record = logging.getLogger().makeRecord(\n            raw_record[\"name\"],\n            raw_record[\"level\"].no,\n            raw_record[\"file\"].path,\n            raw_record[\"line\"],\n            message,\n            (),\n            (exc.type, exc.value, exc.traceback) if exc else None,\n            raw_record[\"function\"],\n            {\"extra\": raw_record[\"extra\"]},\n        )\n\n        # By default, the standard logging module will format the exception and assign it to the\n        # \"exc_text\" attribute. Then, the formatted exception will be automatically appended to the\n        # message when the record is formatted. This is a problem, because that would cause the\n        # exception to be duplicated in the log message, since it's also formatted by Loguru. To\n        # avoid this, we set \"exc_text\" to a simple newline character, which will end the message.\n        if exc:\n            record.exc_text = \"\\n\"\n\n        record.levelname = raw_record[\"level\"].name\n        self._handler.handle(record)"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 91,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StandardSink.stop",
      "span": [
        90,
        92
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def stop(self):\n        \"\"\"Close the logging handler.\"\"\"\n        self._handler.close()",
      "old_code": "    def stop(self):\n        self._handler.close()"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 95,
      "kind": "function",
      "qualname": "loguru._simple_sinks.StandardSink.tasks_to_complete",
      "span": [
        94,
        101
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: Empty list as standard sink has no async tasks.\n        \"\"\"\n        return []",
      "old_code": "    def tasks_to_complete(self):\n        return []"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 105,
      "kind": "class",
      "qualname": "loguru._simple_sinks.AsyncSink",
      "span": [
        104,
        183
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class AsyncSink:\n    \"\"\"A sink that handles asynchronous logging operations.\n\n    Args:\n        function: The async function to execute.\n        loop: The event loop to use.\n        error_interceptor: An interceptor for handling errors.\n    \"\"\"\n\n    def __init__(self, function, loop, error_interceptor):\n        self._function = function\n        self._loop = loop\n        self._error_interceptor = error_interceptor\n        self._tasks = weakref.WeakSet()\n\n    def write(self, message):\n        \"\"\"Asynchronously write a message.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        try:\n            loop = self._loop or get_running_loop()\n        except RuntimeError:\n            return\n\n        coroutine = self._function(message)\n        task = loop.create_task(coroutine)\n\n        def check_exception(future):\n            if future.cancelled() or future.exception() is None:\n                return\n            if not self._error_interceptor.should_catch():\n                raise future.exception()\n            self._error_interceptor.print(message.record, exception=future.exception())\n\n        task.add_done_callback(check_exception)\n        self._tasks.add(task)\n\n    def stop(self):\n        \"\"\"Cancel all pending tasks.\"\"\"\n        for task in self._tasks:\n            task.cancel()\n\n    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: List of tasks to complete.\n        \"\"\"\n        # To avoid errors due to \"self._tasks\" being mutated while iterated, the\n        # \"tasks_to_complete()\" method must be protected by the same lock as \"write()\" (which\n        # happens to be the handler lock). However, the tasks must not be awaited while the lock is\n        # acquired as this could lead to a deadlock. Therefore, we first need to collect the tasks\n        # to complete, then return them so that they can be awaited outside of the lock.\n        return [self._complete_task(task) for task in self._tasks]\n\n    async def _complete_task(self, task):\n        \"\"\"Complete a single task.\n\n        Args:\n            task: The task to complete.\n        \"\"\"\n        loop = get_running_loop()\n        if get_task_loop(task) is not loop:\n            return\n        try:\n            await task\n        except Exception:\n            pass  # Handled in \"check_exception()\"\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        state[\"_tasks\"] = None\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self._tasks = weakref.WeakSet()",
      "old_code": "class AsyncSink:\n    def __init__(self, function, loop, error_interceptor):\n        self._function = function\n        self._loop = loop\n        self._error_interceptor = error_interceptor\n        self._tasks = weakref.WeakSet()\n\n    def write(self, message):\n        try:\n            loop = self._loop or get_running_loop()\n        except RuntimeError:\n            return\n\n        coroutine = self._function(message)\n        task = loop.create_task(coroutine)\n\n        def check_exception(future):\n            if future.cancelled() or future.exception() is None:\n                return\n            if not self._error_interceptor.should_catch():\n                raise future.exception()\n            self._error_interceptor.print(message.record, exception=future.exception())\n\n        task.add_done_callback(check_exception)\n        self._tasks.add(task)\n\n    def stop(self):\n        for task in self._tasks:\n            task.cancel()\n\n    def tasks_to_complete(self):\n        # To avoid errors due to \"self._tasks\" being mutated while iterated, the\n        # \"tasks_to_complete()\" method must be protected by the same lock as \"write()\" (which\n        # happens to be the handler lock). However, the tasks must not be awaited while the lock is\n        # acquired as this could lead to a deadlock. Therefore, we first need to collect the tasks\n        # to complete, then return them so that they can be awaited outside of the lock.\n        return [self._complete_task(task) for task in self._tasks]\n\n    async def _complete_task(self, task):\n        loop = get_running_loop()\n        if get_task_loop(task) is not loop:\n            return\n        try:\n            await task\n        except Exception:\n            pass  # Handled in \"check_exception()\"\n\n    def __getstate__(self):\n        state = self.__dict__.copy()\n        state[\"_tasks\"] = None\n        return state\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        self._tasks = weakref.WeakSet()"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 120,
      "kind": "function",
      "qualname": "loguru._simple_sinks.AsyncSink.write",
      "span": [
        119,
        141
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def write(self, message):\n        \"\"\"Asynchronously write a message.\n\n        Args:\n            message: The message to write.\n        \"\"\"\n        try:\n            loop = self._loop or get_running_loop()\n        except RuntimeError:\n            return\n\n        coroutine = self._function(message)\n        task = loop.create_task(coroutine)\n\n        def check_exception(future):\n            if future.cancelled() or future.exception() is None:\n                return\n            if not self._error_interceptor.should_catch():\n                raise future.exception()\n            self._error_interceptor.print(message.record, exception=future.exception())\n\n        task.add_done_callback(check_exception)\n        self._tasks.add(task)",
      "old_code": "    def write(self, message):\n        try:\n            loop = self._loop or get_running_loop()\n        except RuntimeError:\n            return\n\n        coroutine = self._function(message)\n        task = loop.create_task(coroutine)\n\n        def check_exception(future):\n            if future.cancelled() or future.exception() is None:\n                return\n            if not self._error_interceptor.should_catch():\n                raise future.exception()\n            self._error_interceptor.print(message.record, exception=future.exception())\n\n        task.add_done_callback(check_exception)\n        self._tasks.add(task)"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 144,
      "kind": "function",
      "qualname": "loguru._simple_sinks.AsyncSink.stop",
      "span": [
        143,
        146
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def stop(self):\n        \"\"\"Cancel all pending tasks.\"\"\"\n        for task in self._tasks:\n            task.cancel()",
      "old_code": "    def stop(self):\n        for task in self._tasks:\n            task.cancel()"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 149,
      "kind": "function",
      "qualname": "loguru._simple_sinks.AsyncSink.tasks_to_complete",
      "span": [
        148,
        160
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: List of tasks to complete.\n        \"\"\"\n        # To avoid errors due to \"self._tasks\" being mutated while iterated, the\n        # \"tasks_to_complete()\" method must be protected by the same lock as \"write()\" (which\n        # happens to be the handler lock). However, the tasks must not be awaited while the lock is\n        # acquired as this could lead to a deadlock. Therefore, we first need to collect the tasks\n        # to complete, then return them so that they can be awaited outside of the lock.\n        return [self._complete_task(task) for task in self._tasks]",
      "old_code": "    def tasks_to_complete(self):\n        # To avoid errors due to \"self._tasks\" being mutated while iterated, the\n        # \"tasks_to_complete()\" method must be protected by the same lock as \"write()\" (which\n        # happens to be the handler lock). However, the tasks must not be awaited while the lock is\n        # acquired as this could lead to a deadlock. Therefore, we first need to collect the tasks\n        # to complete, then return them so that they can be awaited outside of the lock.\n        return [self._complete_task(task) for task in self._tasks]"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 163,
      "kind": "async_function",
      "qualname": "loguru._simple_sinks.AsyncSink._complete_task",
      "span": [
        162,
        174
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    async def _complete_task(self, task):\n        \"\"\"Complete a single task.\n\n        Args:\n            task: The task to complete.\n        \"\"\"\n        loop = get_running_loop()\n        if get_task_loop(task) is not loop:\n            return\n        try:\n            await task\n        except Exception:\n            pass  # Handled in \"check_exception()\"",
      "old_code": "    async def _complete_task(self, task):\n        loop = get_running_loop()\n        if get_task_loop(task) is not loop:\n            return\n        try:\n            await task\n        except Exception:\n            pass  # Handled in \"check_exception()\""
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 187,
      "kind": "class",
      "qualname": "loguru._simple_sinks.CallableSink",
      "span": [
        186,
        215
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class CallableSink:\n    \"\"\"A sink that executes a callable function for each log message.\n\n    Args:\n        function: The function to call for each message.\n    \"\"\"\n\n    def __init__(self, function):\n        self._function = function\n\n    def write(self, message):\n        \"\"\"Write a message by calling the function.\n\n        Args:\n            message: The message to pass to the function.\n        \"\"\"\n        self._function(message)\n\n    def stop(self):\n        \"\"\"Stop the sink (no-op for callable sink).\"\"\"\n        pass\n\n    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: Empty list as callable sink has no tasks.\n        \"\"\"\n        return []",
      "old_code": "class CallableSink:\n    def __init__(self, function):\n        self._function = function\n\n    def write(self, message):\n        self._function(message)\n\n    def stop(self):\n        pass\n\n    def tasks_to_complete(self):\n        return []"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 197,
      "kind": "function",
      "qualname": "loguru._simple_sinks.CallableSink.write",
      "span": [
        196,
        202
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def write(self, message):\n        \"\"\"Write a message by calling the function.\n\n        Args:\n            message: The message to pass to the function.\n        \"\"\"\n        self._function(message)",
      "old_code": "    def write(self, message):\n        self._function(message)"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 205,
      "kind": "function",
      "qualname": "loguru._simple_sinks.CallableSink.stop",
      "span": [
        204,
        206
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def stop(self):\n        \"\"\"Stop the sink (no-op for callable sink).\"\"\"\n        pass",
      "old_code": "    def stop(self):\n        pass"
    },
    {
      "path": "loguru/_simple_sinks.py",
      "version": "new",
      "line": 209,
      "kind": "function",
      "qualname": "loguru._simple_sinks.CallableSink.tasks_to_complete",
      "span": [
        208,
        215
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def tasks_to_complete(self):\n        \"\"\"Return list of tasks that need to be completed.\n\n        Returns\n        -------\n            list: Empty list as callable sink has no tasks.\n        \"\"\"\n        return []",
      "old_code": "    def tasks_to_complete(self):\n        return []"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 3,
      "kind": "module",
      "qualname": "loguru._string_parsers",
      "span": null,
      "reason": "diff_new_line_outside_defs",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": null
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 7,
      "kind": "class",
      "qualname": "loguru._string_parsers.Frequencies",
      "span": [
        6,
        86
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class Frequencies:\n    \"\"\"Provide static methods to compute the next occurrence of various time frequencies.\n\n    Includes hourly, daily, weekly, monthly, and yearly frequencies\n    based on a given datetime object.\n    \"\"\"\n\n    @staticmethod\n    def hourly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next hour occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next hour with minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(hours=1)\n        return dt.replace(minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def daily(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next day occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next day with hour, minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(days=1)\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def weekly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next week occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next Monday with hour, minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(days=7 - t.weekday())\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def monthly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next month occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: First day of next month with hour, minutes,\n        seconds, microseconds set to zero.\n        \"\"\"\n        if t.month == 12:\n            y, m = t.year + 1, 1\n        else:\n            y, m = t.year, t.month + 1\n        return t.replace(year=y, month=m, day=1, hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def yearly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next year occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n        datetime.datetime: First day of next year with hour,\n        minutes, seconds, microseconds set to zero.\n        \"\"\"\n        y = t.year + 1\n        return t.replace(year=y, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)",
      "old_code": "class Frequencies:\n    @staticmethod\n    def hourly(t):\n        dt = t + datetime.timedelta(hours=1)\n        return dt.replace(minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def daily(t):\n        dt = t + datetime.timedelta(days=1)\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def weekly(t):\n        dt = t + datetime.timedelta(days=7 - t.weekday())\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def monthly(t):\n        if t.month == 12:\n            y, m = t.year + 1, 1\n        else:\n            y, m = t.year, t.month + 1\n        return t.replace(year=y, month=m, day=1, hour=0, minute=0, second=0, microsecond=0)\n\n    @staticmethod\n    def yearly(t):\n        y = t.year + 1\n        return t.replace(year=y, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 14,
      "kind": "function",
      "qualname": "loguru._string_parsers.Frequencies.hourly",
      "span": [
        14,
        25
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def hourly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next hour occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next hour with minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(hours=1)\n        return dt.replace(minute=0, second=0, microsecond=0)",
      "old_code": "    def hourly(t):\n        dt = t + datetime.timedelta(hours=1)\n        return dt.replace(minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 28,
      "kind": "function",
      "qualname": "loguru._string_parsers.Frequencies.daily",
      "span": [
        28,
        39
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def daily(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next day occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next day with hour, minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(days=1)\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)",
      "old_code": "    def daily(t):\n        dt = t + datetime.timedelta(days=1)\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 42,
      "kind": "function",
      "qualname": "loguru._string_parsers.Frequencies.weekly",
      "span": [
        42,
        53
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def weekly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next week occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: Next Monday with hour, minutes, seconds, microseconds set to zero.\n        \"\"\"\n        dt = t + datetime.timedelta(days=7 - t.weekday())\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)",
      "old_code": "    def weekly(t):\n        dt = t + datetime.timedelta(days=7 - t.weekday())\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 56,
      "kind": "function",
      "qualname": "loguru._string_parsers.Frequencies.monthly",
      "span": [
        56,
        71
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def monthly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next month occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n            datetime.datetime: First day of next month with hour, minutes,\n        seconds, microseconds set to zero.\n        \"\"\"\n        if t.month == 12:\n            y, m = t.year + 1, 1\n        else:\n            y, m = t.year, t.month + 1\n        return t.replace(year=y, month=m, day=1, hour=0, minute=0, second=0, microsecond=0)",
      "old_code": "    def monthly(t):\n        if t.month == 12:\n            y, m = t.year + 1, 1\n        else:\n            y, m = t.year, t.month + 1\n        return t.replace(year=y, month=m, day=1, hour=0, minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 74,
      "kind": "function",
      "qualname": "loguru._string_parsers.Frequencies.yearly",
      "span": [
        74,
        86
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def yearly(t: datetime.datetime) -> datetime.datetime:\n        \"\"\"Compute the next year occurrence.\n\n        Args:\n            t (datetime.datetime): The reference datetime.\n\n        Returns\n        -------\n        datetime.datetime: First day of next year with hour,\n        minutes, seconds, microseconds set to zero.\n        \"\"\"\n        y = t.year + 1\n        return t.replace(year=y, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)",
      "old_code": "    def yearly(t):\n        y = t.year + 1\n        return t.replace(year=y, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 89,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_size",
      "span": [
        89,
        123
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_size(size: str) -> Optional[float]:\n    \"\"\"Parse a size string with optional units into bits.\n\n    Supports formats like '100MB', '2GiB', '1.5TB'. Case insensitive.\n\n    Args:\n        size (str): Size string to parse (e.g., '100MB', '2GiB').\n\n    Returns\n    -------\n        float | None: Size in bits or None if invalid format.\n\n    Raises\n    ------\n        ValueError: If numeric value or unit is invalid.\n    \"\"\"\n    size = size.strip()\n    reg = re.compile(r\"([e\\+\\-\\.\\d]+)\\s*([kmgtpezy])?(i)?(b)\", flags=re.I)\n\n    match = reg.fullmatch(size)\n\n    if not match:\n        return None\n\n    s, u, i, b = match.groups()\n\n    try:\n        s = float(s)\n    except ValueError as err:\n        raise ValueError(\"Invalid float value while parsing size: '%s'\" % s) from err\n\n    u = \"kmgtpezy\".index(u.lower()) + 1 if u else 0\n    i = 1024 if i else 1000\n    b = {\"b\": 8, \"B\": 1}[b] if b else 1\n    return s * i**u / b",
      "old_code": "def parse_size(size):\n    size = size.strip()\n    reg = re.compile(r\"([e\\+\\-\\.\\d]+)\\s*([kmgtpezy])?(i)?(b)\", flags=re.I)\n\n    match = reg.fullmatch(size)\n\n    if not match:\n        return None\n\n    s, u, i, b = match.groups()\n\n    try:\n        s = float(s)\n    except ValueError as e:\n        raise ValueError(\"Invalid float value while parsing size: '%s'\" % s) from e\n\n    u = \"kmgtpezy\".index(u.lower()) + 1 if u else 0\n    i = 1024 if i else 1000\n    b = {\"b\": 8, \"B\": 1}[b] if b else 1\n    return s * i**u / b"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 126,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_duration",
      "span": [
        126,
        176
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_duration(duration: str) -> Optional[datetime.timedelta]:\n    \"\"\"Parse a duration string and return a corresponding timedelta object.\n\n    The string can include multiple units (years, months, weeks, days, hours, minutes, seconds).\n    Example: \"1h 30min\", \"2 days, 3h\", \"1.5y 2months\".\n\n    Args:\n        duration (str): The duration string to parse.\n\n    Returns\n    -------\n        datetime.timedelta | None: The parsed duration or None if input is invalid.\n\n    Raises\n    ------\n        ValueError: If a value cannot be converted to float or if an invalid unit is encountered.\n    \"\"\"\n    duration = duration.strip()\n    reg = r\"(?:([e\\+\\-\\.\\d]+)\\s*([a-z]+)[\\s\\,]*)\"\n\n    units = [\n        (\"y|years?\", 31536000),\n        (\"months?\", 2628000),\n        (\"w|weeks?\", 604800),\n        (\"d|days?\", 86400),\n        (\"h|hours?\", 3600),\n        (\"min(?:ute)?s?\", 60),\n        (\"s|sec(?:ond)?s?\", 1),  # spellchecker: disable-line\n        (\"ms|milliseconds?\", 0.001),\n        (\"us|microseconds?\", 0.000001),\n    ]\n\n    if not re.fullmatch(reg + \"+\", duration, flags=re.I):\n        return None\n\n    seconds = 0\n\n    for value, unit in re.findall(reg, duration, flags=re.I):\n        try:\n            value = float(value)\n        except ValueError as e:\n            raise ValueError(\"Invalid float value while parsing duration: '%s'\" % value) from e\n\n        try:\n            unit = next(u for r, u in units if re.fullmatch(r, unit, flags=re.I))\n        except StopIteration:\n            raise ValueError(\"Invalid unit value while parsing duration: '%s'\" % unit) from None\n\n        seconds += value * unit\n\n    return datetime.timedelta(seconds=seconds)",
      "old_code": "def parse_duration(duration):\n    duration = duration.strip()\n    reg = r\"(?:([e\\+\\-\\.\\d]+)\\s*([a-z]+)[\\s\\,]*)\"\n\n    units = [\n        (\"y|years?\", 31536000),\n        (\"months?\", 2628000),\n        (\"w|weeks?\", 604800),\n        (\"d|days?\", 86400),\n        (\"h|hours?\", 3600),\n        (\"min(?:ute)?s?\", 60),\n        (\"s|sec(?:ond)?s?\", 1),  # spellchecker: disable-line\n        (\"ms|milliseconds?\", 0.001),\n        (\"us|microseconds?\", 0.000001),\n    ]\n\n    if not re.fullmatch(reg + \"+\", duration, flags=re.I):\n        return None\n\n    seconds = 0\n\n    for value, unit in re.findall(reg, duration, flags=re.I):\n        try:\n            value = float(value)\n        except ValueError as e:\n            raise ValueError(\"Invalid float value while parsing duration: '%s'\" % value) from e\n\n        try:\n            unit = next(u for r, u in units if re.fullmatch(r, unit, flags=re.I))\n        except StopIteration:\n            raise ValueError(\"Invalid unit value while parsing duration: '%s'\" % unit) from None\n\n        seconds += value * unit\n\n    return datetime.timedelta(seconds=seconds)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 179,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_frequency",
      "span": [
        179,
        199
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_frequency(frequency: str):\n    \"\"\"Parse a frequency string and return the corresponding Frequencies method.\n\n    Supported frequencies: hourly, daily, weekly, monthly, yearly.\n\n    Args:\n        frequency (str): The frequency string.\n\n    Returns\n    -------\n        Callable | None: Corresponding Frequencies method or None if unrecognized.\n    \"\"\"\n    frequencies = {\n        \"hourly\": Frequencies.hourly,\n        \"daily\": Frequencies.daily,\n        \"weekly\": Frequencies.weekly,\n        \"monthly\": Frequencies.monthly,\n        \"yearly\": Frequencies.yearly,\n    }\n    frequency = frequency.strip().lower()\n    return frequencies.get(frequency, None)",
      "old_code": "def parse_frequency(frequency):\n    frequencies = {\n        \"hourly\": Frequencies.hourly,\n        \"daily\": Frequencies.daily,\n        \"weekly\": Frequencies.weekly,\n        \"monthly\": Frequencies.monthly,\n        \"yearly\": Frequencies.yearly,\n    }\n    frequency = frequency.strip().lower()\n    return frequencies.get(frequency, None)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 202,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_day",
      "span": [
        202,
        237
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_day(day: str) -> Optional[int]:\n    \"\"\"Parse a weekday string and return its integer value.\n\n    Accepts full day names or \"w0\" to \"w6\".\n\n    Args:\n        day (str): The day to parse.\n\n    Returns\n    -------\n        int | None: Integer value (Monday=0  Sunday=6), or None if invalid.\n\n    Raises\n    ------\n        ValueError: If the digit in 'wX' is not in range [0-6].\n    \"\"\"\n    days = {\n        \"monday\": 0,\n        \"tuesday\": 1,\n        \"wednesday\": 2,\n        \"thursday\": 3,\n        \"friday\": 4,\n        \"saturday\": 5,\n        \"sunday\": 6,\n    }\n    day = day.strip().lower()\n    if day in days:\n        return days[day]\n    if day.startswith(\"w\") and day[1:].isdigit():\n        day = int(day[1:])\n        if not 0 <= day < 7:\n            raise ValueError(\"Invalid weekday value while parsing day (expected [0-6]): '%d'\" % day)\n    else:\n        day = None\n\n    return day",
      "old_code": "def parse_day(day):\n    days = {\n        \"monday\": 0,\n        \"tuesday\": 1,\n        \"wednesday\": 2,\n        \"thursday\": 3,\n        \"friday\": 4,\n        \"saturday\": 5,\n        \"sunday\": 6,\n    }\n    day = day.strip().lower()\n    if day in days:\n        return days[day]\n    if day.startswith(\"w\") and day[1:].isdigit():\n        day = int(day[1:])\n        if not 0 <= day < 7:\n            raise ValueError(\"Invalid weekday value while parsing day (expected [0-6]): '%d'\" % day)\n    else:\n        day = None\n\n    return day"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 240,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_time",
      "span": [
        240,
        281
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_time(time: str) -> datetime.time:\n    \"\"\"Parse a time string and return a `datetime.time` object.\n\n    Supports formats: HH, HH:MM, HH:MM:SS, HH AM/PM, etc.\n\n    Args:\n        time (str): The time string.\n\n    Returns\n    -------\n        datetime.time: The parsed time.\n\n    Raises\n    ------\n        ValueError: If input doesn't match any supported format.\n    \"\"\"\n    time = time.strip()\n    reg = re.compile(r\"^[\\d\\.\\:]+\\s*(?:[ap]m)?$\", flags=re.I)\n\n    if not reg.match(time):\n        return None\n\n    formats = [\n        \"%H\",\n        \"%H:%M\",\n        \"%H:%M:%S\",\n        \"%H:%M:%S.%f\",\n        \"%I %p\",\n        \"%I:%M %S\",\n        \"%I:%M:%S %p\",\n        \"%I:%M:%S.%f %p\",\n    ]\n\n    for format_ in formats:\n        try:\n            dt = datetime.datetime.strptime(time, format_)\n        except ValueError:\n            pass\n        else:\n            return dt.time()\n\n    raise ValueError(\"Unrecognized format while parsing time: '%s'\" % time)",
      "old_code": "def parse_time(time):\n    time = time.strip()\n    reg = re.compile(r\"^[\\d\\.\\:]+\\s*(?:[ap]m)?$\", flags=re.I)\n\n    if not reg.match(time):\n        return None\n\n    formats = [\n        \"%H\",\n        \"%H:%M\",\n        \"%H:%M:%S\",\n        \"%H:%M:%S.%f\",\n        \"%I %p\",\n        \"%I:%M %S\",\n        \"%I:%M:%S %p\",\n        \"%I:%M:%S.%f %p\",\n    ]\n\n    for format_ in formats:\n        try:\n            dt = datetime.datetime.strptime(time, format_)\n        except ValueError:\n            pass\n        else:\n            return dt.time()\n\n    raise ValueError(\"Unrecognized format while parsing time: '%s'\" % time)"
    },
    {
      "path": "loguru/_string_parsers.py",
      "version": "new",
      "line": 284,
      "kind": "function",
      "qualname": "loguru._string_parsers.parse_daytime",
      "span": [
        284,
        324
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def parse_daytime(daytime: str) -> Optional[Tuple[int, datetime.time]]:\n    \"\"\"Parse a string representing a day and time separated by 'at'.\n\n    Args:\n        daytime (str): The day and time string.\n\n    Returns\n    -------\n        tuple[int, datetime.time] | None: Parsed (day, time) or None.\n\n    Raises\n    ------\n        ValueError: If the day or time cannot be parsed.\n    \"\"\"\n    daytime = daytime.strip()\n    reg = re.compile(r\"^(.*?)\\s+at\\s+(.*)$\", flags=re.I)\n\n    match = reg.match(daytime)\n    if match:\n        day, time = match.groups()\n    else:\n        day = time = daytime\n\n    try:\n        parsed_day = parse_day(day)\n        if match and parsed_day is None:\n            raise ValueError(\"Unparsable day\")\n    except ValueError as e:\n        raise ValueError(\"Invalid day while parsing daytime: '%s'\" % day) from e\n\n    try:\n        parsed_time = parse_time(time)\n        if match and parsed_time is None:\n            raise ValueError(\"Unparsable time\")\n    except ValueError as e:\n        raise ValueError(\"Invalid time while parsing daytime: '%s'\" % time) from e\n\n    if parsed_day is None and parsed_time is None:\n        return None\n\n    return parsed_day, parsed_time",
      "old_code": "def parse_daytime(daytime):\n    daytime = daytime.strip()\n    reg = re.compile(r\"^(.*?)\\s+at\\s+(.*)$\", flags=re.I)\n\n    match = reg.match(daytime)\n    if match:\n        day, time = match.groups()\n    else:\n        day = time = daytime\n\n    try:\n        parsed_day = parse_day(day)\n        if match and parsed_day is None:\n            raise ValueError(\"Unparsable day\")\n    except ValueError as e:\n        raise ValueError(\"Invalid day while parsing daytime: '%s'\" % day) from e\n\n    try:\n        parsed_time = parse_time(time)\n        if match and parsed_time is None:\n            raise ValueError(\"Unparsable time\")\n    except ValueError as e:\n        raise ValueError(\"Invalid time while parsing daytime: '%s'\" % time) from e\n\n    if parsed_day is None and parsed_time is None:\n        return None\n\n    return parsed_day, parsed_time"
    }
  ],
  "generated_at": "2026-02-10T15:14:09"
}