{
  "commit": "5028ce6e",
  "parent": "4b715f3a72d055c56d667d5265c28d3bb9e14abd",
  "repo": "D:\\locbench\\peewee",
  "num_files_in_diff": 6,
  "num_py_files_in_diff": 3,
  "num_seeds": 17,
  "seeds": [
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3593,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase.__init__",
      "span": [
        3586,
        3598
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, database, *args, **kwargs):\n        self._pragmas = kwargs.pop('pragmas', ())\n        super(SqliteDatabase, self).__init__(database, *args, **kwargs)\n        self._aggregates = {}\n        self._collations = {}\n        self._functions = {}\n        self._window_functions = {}\n        self._extensions = set()\n        self._attached = {}\n        self.register_function(_sqlite_date_part, 'date_part', 2)\n        self.register_function(_sqlite_date_trunc, 'date_trunc', 2)\n        self.nulls_ordering = self.server_version >= (3, 30, 0)",
      "old_code": "    def __init__(self, database, *args, **kwargs):\n        self._pragmas = kwargs.pop('pragmas', ())\n        super(SqliteDatabase, self).__init__(database, *args, **kwargs)\n        self._aggregates = {}\n        self._collations = {}\n        self._functions = {}\n        self._window_functions = {}\n        self._table_functions = []\n        self._extensions = set()\n        self._attached = {}\n        self.register_function(_sqlite_date_part, 'date_part', 2)\n        self.register_function(_sqlite_date_trunc, 'date_trunc', 2)\n        self.nulls_ordering = self.server_version >= (3, 30, 0)"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3638,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase._add_conn_hooks",
      "span": [
        3628,
        3642
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def _add_conn_hooks(self, conn):\n        if self._attached:\n            self._attach_databases(conn)\n        if self._pragmas:\n            self._set_pragmas(conn)\n        self._load_aggregates(conn)\n        self._load_collations(conn)\n        self._load_functions(conn)\n        if self.server_version >= (3, 25, 0):\n            self._load_window_functions(conn)\n        if self._extensions:\n            self._load_extensions(conn)",
      "old_code": "    def _add_conn_hooks(self, conn):\n        if self._attached:\n            self._attach_databases(conn)\n        if self._pragmas:\n            self._set_pragmas(conn)\n        self._load_aggregates(conn)\n        self._load_collations(conn)\n        self._load_functions(conn)\n        if self.server_version >= (3, 25, 0):\n            self._load_window_functions(conn)\n        if self._table_functions:\n            for table_function in self._table_functions:\n                table_function.register(conn)\n        if self._extensions:\n            self._load_extensions(conn)"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3768,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase.register_table_function",
      "span": [
        3768,
        3773
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": "    def register_table_function(self, klass, name=None):\n        if name is not None:\n            klass.name = name\n        self._table_functions.append(klass)\n        if not self.is_closed():\n            klass.register(self.connection())"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3774,
      "kind": "class",
      "qualname": "peewee.SqliteDatabase",
      "span": [
        3570,
        3973
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class SqliteDatabase(Database):\n    field_types = {\n        'BIGAUTO': FIELD.AUTO,\n        'BIGINT': FIELD.INT,\n        'BOOL': FIELD.INT,\n        'DOUBLE': FIELD.FLOAT,\n        'SMALLINT': FIELD.INT,\n        'UUID': FIELD.TEXT}\n    operations = {\n        'LIKE': 'GLOB',\n        'ILIKE': 'LIKE'}\n    index_schema_prefix = True\n    limit_max = -1\n    server_version = __sqlite_version__\n    truncate_table = False\n\n    def __init__(self, database, *args, **kwargs):\n        self._pragmas = kwargs.pop('pragmas', ())\n        super(SqliteDatabase, self).__init__(database, *args, **kwargs)\n        self._aggregates = {}\n        self._collations = {}\n        self._functions = {}\n        self._window_functions = {}\n        self._extensions = set()\n        self._attached = {}\n        self.register_function(_sqlite_date_part, 'date_part', 2)\n        self.register_function(_sqlite_date_trunc, 'date_trunc', 2)\n        self.nulls_ordering = self.server_version >= (3, 30, 0)\n\n    def init(self, database, pragmas=None, timeout=5, returning_clause=None,\n             **kwargs):\n        if pragmas is not None:\n            self._pragmas = pragmas\n        if isinstance(self._pragmas, dict):\n            self._pragmas = list(self._pragmas.items())\n        if returning_clause is not None:\n            if __sqlite_version__ < (3, 35, 0):\n                warnings.warn('RETURNING clause requires Sqlite 3.35 or newer')\n            self.returning_clause = returning_clause\n        self._timeout = timeout\n        super(SqliteDatabase, self).init(database, **kwargs)\n\n    def _set_server_version(self, conn):\n        pass\n\n    def _connect(self):\n        if sqlite3 is None:\n            raise ImproperlyConfigured('SQLite driver not installed!')\n        conn = sqlite3.connect(self.database, timeout=self._timeout,\n                               isolation_level=None, **self.connect_params)\n        try:\n            self._add_conn_hooks(conn)\n        except:\n            conn.close()\n            raise\n        return conn\n\n    def _add_conn_hooks(self, conn):\n        if self._attached:\n            self._attach_databases(conn)\n        if self._pragmas:\n            self._set_pragmas(conn)\n        self._load_aggregates(conn)\n        self._load_collations(conn)\n        self._load_functions(conn)\n        if self.server_version >= (3, 25, 0):\n            self._load_window_functions(conn)\n        if self._extensions:\n            self._load_extensions(conn)\n\n    def _set_pragmas(self, conn):\n        cursor = conn.cursor()\n        for pragma, value in self._pragmas:\n            cursor.execute('PRAGMA %s = %s;' % (pragma, value))\n        cursor.close()\n\n    def _attach_databases(self, conn):\n        cursor = conn.cursor()\n        for name, db in self._attached.items():\n            cursor.execute('ATTACH DATABASE \"%s\" AS \"%s\"' % (db, name))\n        cursor.close()\n\n    def pragma(self, key, value=SENTINEL, permanent=False, schema=None):\n        if schema is not None:\n            key = '\"%s\".%s' % (schema, key)\n        sql = 'PRAGMA %s' % key\n        if value is not SENTINEL:\n            sql += ' = %s' % (value or 0)\n            if permanent:\n                pragmas = dict(self._pragmas or ())\n                pragmas[key] = value\n                self._pragmas = list(pragmas.items())\n        elif permanent:\n            raise ValueError('Cannot specify a permanent pragma without value')\n        row = self.execute_sql(sql).fetchone()\n        if row:\n            return row[0]\n\n    cache_size = __pragma__('cache_size')\n    foreign_keys = __pragma__('foreign_keys')\n    journal_mode = __pragma__('journal_mode')\n    journal_size_limit = __pragma__('journal_size_limit')\n    mmap_size = __pragma__('mmap_size')\n    page_size = __pragma__('page_size')\n    read_uncommitted = __pragma__('read_uncommitted')\n    synchronous = __pragma__('synchronous')\n    wal_autocheckpoint = __pragma__('wal_autocheckpoint')\n    application_id = __pragma__('application_id')\n    user_version = __pragma__('user_version')\n    data_version = __pragma__('data_version')\n\n    @property\n    def timeout(self):\n        return self._timeout\n\n    @timeout.setter\n    def timeout(self, seconds):\n        if self._timeout == seconds:\n            return\n\n        self._timeout = seconds\n        if not self.is_closed():\n            # PySQLite multiplies user timeout by 1000, but the unit of the\n            # timeout PRAGMA is actually milliseconds.\n            self.execute_sql('PRAGMA busy_timeout=%d;' % (seconds * 1000))\n\n    def _load_aggregates(self, conn):\n        for name, (klass, num_params) in self._aggregates.items():\n            conn.create_aggregate(name, num_params, klass)\n\n    def _load_collations(self, conn):\n        for name, fn in self._collations.items():\n            conn.create_collation(name, fn)\n\n    def _load_functions(self, conn):\n        for name, (fn, n_params, deterministic) in self._functions.items():\n            kwargs = {'deterministic': deterministic} if deterministic else {}\n            conn.create_function(name, n_params, fn, **kwargs)\n\n    def _load_window_functions(self, conn):\n        for name, (klass, num_params) in self._window_functions.items():\n            conn.create_window_function(name, num_params, klass)\n\n    def register_aggregate(self, klass, name=None, num_params=-1):\n        self._aggregates[name or klass.__name__.lower()] = (klass, num_params)\n        if not self.is_closed():\n            self._load_aggregates(self.connection())\n\n    def aggregate(self, name=None, num_params=-1):\n        def decorator(klass):\n            self.register_aggregate(klass, name, num_params)\n            return klass\n        return decorator\n\n    def register_collation(self, fn, name=None):\n        name = name or fn.__name__\n        def _collation(*args):\n            expressions = args + (SQL('collate %s' % name),)\n            return NodeList(expressions)\n        fn.collation = _collation\n        self._collations[name] = fn\n        if not self.is_closed():\n            self._load_collations(self.connection())\n\n    def collation(self, name=None):\n        def decorator(fn):\n            self.register_collation(fn, name)\n            return fn\n        return decorator\n\n    def register_function(self, fn, name=None, num_params=-1,\n                          deterministic=None):\n        self._functions[name or fn.__name__] = (fn, num_params, deterministic)\n        if not self.is_closed():\n            self._load_functions(self.connection())\n\n    def func(self, name=None, num_params=-1, deterministic=None):\n        def decorator(fn):\n            self.register_function(fn, name, num_params, deterministic)\n            return fn\n        return decorator\n\n    def register_window_function(self, klass, name=None, num_params=-1):\n        name = name or klass.__name__.lower()\n        self._window_functions[name] = (klass, num_params)\n        if not self.is_closed():\n            self._load_window_functions(self.connection())\n\n    def window_function(self, name=None, num_params=-1):\n        def decorator(klass):\n            self.register_window_function(klass, name, num_params)\n            return klass\n        return decorator\n\n    def unregister_aggregate(self, name):\n        del(self._aggregates[name])\n\n    def unregister_collation(self, name):\n        del(self._collations[name])\n\n    def unregister_function(self, name):\n        del(self._functions[name])\n\n    def unregister_window_function(self, name):\n        del(self._window_functions[name])\n\n    def _load_extensions(self, conn):\n        conn.enable_load_extension(True)\n        for extension in self._extensions:\n            conn.load_extension(extension)\n\n    def load_extension(self, extension):\n        self._extensions.add(extension)\n        if not self.is_closed():\n            conn = self.connection()\n            conn.enable_load_extension(True)\n            conn.load_extension(extension)\n\n    def unload_extension(self, extension):\n        self._extensions.remove(extension)\n\n    def attach(self, filename, name):\n        if name in self._attached:\n            if self._attached[name] == filename:\n                return False\n            raise OperationalError('schema \"%s\" already attached.' % name)\n\n        self._attached[name] = filename\n        if not self.is_closed():\n            self.execute_sql('ATTACH DATABASE \"%s\" AS \"%s\"' % (filename, name))\n        return True\n\n    def detach(self, name):\n        if name not in self._attached:\n            return False\n\n        del self._attached[name]\n        if not self.is_closed():\n            self.execute_sql('DETACH DATABASE \"%s\"' % name)\n        return True\n\n    def last_insert_id(self, cursor, query_type=None):\n        if not self.returning_clause:\n            return cursor.lastrowid\n        elif query_type == Insert.SIMPLE:\n            try:\n                return cursor[0][0]\n            except (IndexError, KeyError, TypeError):\n                pass\n        return cursor\n\n    def rows_affected(self, cursor):\n        try:\n            return cursor.rowcount\n        except AttributeError:\n            return cursor.cursor.rowcount  # This was a RETURNING query.\n\n    def begin(self, lock_type=None):\n        statement = 'BEGIN %s' % lock_type if lock_type else 'BEGIN'\n        self.execute_sql(statement)\n\n    def commit(self):\n        with __exception_wrapper__:\n            return self.execute_sql('COMMIT')\n\n    def rollback(self):\n        with __exception_wrapper__:\n            return self.execute_sql('ROLLBACK')\n\n    def get_tables(self, schema=None):\n        schema = schema or 'main'\n        cursor = self.execute_sql('SELECT name FROM \"%s\".sqlite_master WHERE '\n                                  'type=? ORDER BY name' % schema, ('table',))\n        return [row for row, in cursor.fetchall()]\n\n    def get_views(self, schema=None):\n        sql = ('SELECT name, sql FROM \"%s\".sqlite_master WHERE type=? '\n               'ORDER BY name') % (schema or 'main')\n        return [ViewMetadata(*row) for row in self.execute_sql(sql, ('view',))]\n\n    def get_indexes(self, table, schema=None):\n        schema = schema or 'main'\n        query = ('SELECT name, sql FROM \"%s\".sqlite_master '\n                 'WHERE tbl_name = ? AND type = ? ORDER BY name') % schema\n        cursor = self.execute_sql(query, (table, 'index'))\n        index_to_sql = dict(cursor.fetchall())\n\n        # Determine which indexes have a unique constraint.\n        unique_indexes = set()\n        cursor = self.execute_sql('PRAGMA \"%s\".index_list(\"%s\")' %\n                                  (schema, table))\n        for row in cursor.fetchall():\n            name = row[1]\n            is_unique = int(row[2]) == 1\n            if is_unique:\n                unique_indexes.add(name)\n\n        # Retrieve the indexed columns.\n        index_columns = {}\n        for index_name in sorted(index_to_sql):\n            cursor = self.execute_sql('PRAGMA \"%s\".index_info(\"%s\")' %\n                                      (schema, index_name))\n            index_columns[index_name] = [row[2] for row in cursor.fetchall()]\n\n        return [\n            IndexMetadata(\n                name,\n                index_to_sql[name],\n                index_columns[name],\n                name in unique_indexes,\n                table)\n            for name in sorted(index_to_sql)]\n\n    def get_columns(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".table_info(\"%s\")' %\n                                  (schema or 'main', table))\n        return [ColumnMetadata(r[1], r[2], not r[3], bool(r[5]), table, r[4])\n                for r in cursor.fetchall()]\n\n    def get_primary_keys(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".table_info(\"%s\")' %\n                                  (schema or 'main', table))\n        return [row[1] for row in filter(lambda r: r[-1], cursor.fetchall())]\n\n    def get_foreign_keys(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".foreign_key_list(\"%s\")' %\n                                  (schema or 'main', table))\n        return [ForeignKeyMetadata(row[3], row[2], row[4], table)\n                for row in cursor.fetchall()]\n\n    def get_binary_type(self):\n        return sqlite3.Binary\n\n    def conflict_statement(self, on_conflict, query):\n        action = on_conflict._action.lower() if on_conflict._action else ''\n        if action and action not in ('nothing', 'update'):\n            return SQL('INSERT OR %s' % on_conflict._action.upper())\n\n    def conflict_update(self, oc, query):\n        # Sqlite prior to 3.24.0 does not support Postgres-style upsert.\n        if self.server_version < (3, 24, 0) and \\\n           any((oc._preserve, oc._update, oc._where, oc._conflict_target,\n                oc._conflict_constraint)):\n            raise ValueError('SQLite does not support specifying which values '\n                             'to preserve or update.')\n\n        action = oc._action.lower() if oc._action else ''\n        if action and action not in ('nothing', 'update', ''):\n            return\n\n        if action == 'nothing':\n            return SQL('ON CONFLICT DO NOTHING')\n        elif not oc._update and not oc._preserve:\n            raise ValueError('If you are not performing any updates (or '\n                             'preserving any INSERTed values), then the '\n                             'conflict resolution action should be set to '\n                             '\"NOTHING\".')\n        elif oc._conflict_constraint:\n            raise ValueError('SQLite does not support specifying named '\n                             'constraints for conflict resolution.')\n        elif not oc._conflict_target:\n            raise ValueError('SQLite requires that a conflict target be '\n                             'specified when doing an upsert.')\n\n        return self._build_on_conflict_update(oc, query)\n\n    def extract_date(self, date_part, date_field):\n        return fn.date_part(date_part, date_field, python_value=int)\n\n    def truncate_date(self, date_part, date_field):\n        return fn.date_trunc(date_part, date_field,\n                             python_value=simple_date_time)\n\n    def to_timestamp(self, date_field):\n        return fn.strftime('%s', date_field).cast('integer')\n\n    def from_timestamp(self, date_field):\n        return fn.datetime(date_field, 'unixepoch')",
      "old_code": "class SqliteDatabase(Database):\n    field_types = {\n        'BIGAUTO': FIELD.AUTO,\n        'BIGINT': FIELD.INT,\n        'BOOL': FIELD.INT,\n        'DOUBLE': FIELD.FLOAT,\n        'SMALLINT': FIELD.INT,\n        'UUID': FIELD.TEXT}\n    operations = {\n        'LIKE': 'GLOB',\n        'ILIKE': 'LIKE'}\n    index_schema_prefix = True\n    limit_max = -1\n    server_version = __sqlite_version__\n    truncate_table = False\n\n    def __init__(self, database, *args, **kwargs):\n        self._pragmas = kwargs.pop('pragmas', ())\n        super(SqliteDatabase, self).__init__(database, *args, **kwargs)\n        self._aggregates = {}\n        self._collations = {}\n        self._functions = {}\n        self._window_functions = {}\n        self._table_functions = []\n        self._extensions = set()\n        self._attached = {}\n        self.register_function(_sqlite_date_part, 'date_part', 2)\n        self.register_function(_sqlite_date_trunc, 'date_trunc', 2)\n        self.nulls_ordering = self.server_version >= (3, 30, 0)\n\n    def init(self, database, pragmas=None, timeout=5, returning_clause=None,\n             **kwargs):\n        if pragmas is not None:\n            self._pragmas = pragmas\n        if isinstance(self._pragmas, dict):\n            self._pragmas = list(self._pragmas.items())\n        if returning_clause is not None:\n            if __sqlite_version__ < (3, 35, 0):\n                warnings.warn('RETURNING clause requires Sqlite 3.35 or newer')\n            self.returning_clause = returning_clause\n        self._timeout = timeout\n        super(SqliteDatabase, self).init(database, **kwargs)\n\n    def _set_server_version(self, conn):\n        pass\n\n    def _connect(self):\n        if sqlite3 is None:\n            raise ImproperlyConfigured('SQLite driver not installed!')\n        conn = sqlite3.connect(self.database, timeout=self._timeout,\n                               isolation_level=None, **self.connect_params)\n        try:\n            self._add_conn_hooks(conn)\n        except:\n            conn.close()\n            raise\n        return conn\n\n    def _add_conn_hooks(self, conn):\n        if self._attached:\n            self._attach_databases(conn)\n        if self._pragmas:\n            self._set_pragmas(conn)\n        self._load_aggregates(conn)\n        self._load_collations(conn)\n        self._load_functions(conn)\n        if self.server_version >= (3, 25, 0):\n            self._load_window_functions(conn)\n        if self._table_functions:\n            for table_function in self._table_functions:\n                table_function.register(conn)\n        if self._extensions:\n            self._load_extensions(conn)\n\n    def _set_pragmas(self, conn):\n        cursor = conn.cursor()\n        for pragma, value in self._pragmas:\n            cursor.execute('PRAGMA %s = %s;' % (pragma, value))\n        cursor.close()\n\n    def _attach_databases(self, conn):\n        cursor = conn.cursor()\n        for name, db in self._attached.items():\n            cursor.execute('ATTACH DATABASE \"%s\" AS \"%s\"' % (db, name))\n        cursor.close()\n\n    def pragma(self, key, value=SENTINEL, permanent=False, schema=None):\n        if schema is not None:\n            key = '\"%s\".%s' % (schema, key)\n        sql = 'PRAGMA %s' % key\n        if value is not SENTINEL:\n            sql += ' = %s' % (value or 0)\n            if permanent:\n                pragmas = dict(self._pragmas or ())\n                pragmas[key] = value\n                self._pragmas = list(pragmas.items())\n        elif permanent:\n            raise ValueError('Cannot specify a permanent pragma without value')\n        row = self.execute_sql(sql).fetchone()\n        if row:\n            return row[0]\n\n    cache_size = __pragma__('cache_size')\n    foreign_keys = __pragma__('foreign_keys')\n    journal_mode = __pragma__('journal_mode')\n    journal_size_limit = __pragma__('journal_size_limit')\n    mmap_size = __pragma__('mmap_size')\n    page_size = __pragma__('page_size')\n    read_uncommitted = __pragma__('read_uncommitted')\n    synchronous = __pragma__('synchronous')\n    wal_autocheckpoint = __pragma__('wal_autocheckpoint')\n    application_id = __pragma__('application_id')\n    user_version = __pragma__('user_version')\n    data_version = __pragma__('data_version')\n\n    @property\n    def timeout(self):\n        return self._timeout\n\n    @timeout.setter\n    def timeout(self, seconds):\n        if self._timeout == seconds:\n            return\n\n        self._timeout = seconds\n        if not self.is_closed():\n            # PySQLite multiplies user timeout by 1000, but the unit of the\n            # timeout PRAGMA is actually milliseconds.\n            self.execute_sql('PRAGMA busy_timeout=%d;' % (seconds * 1000))\n\n    def _load_aggregates(self, conn):\n        for name, (klass, num_params) in self._aggregates.items():\n            conn.create_aggregate(name, num_params, klass)\n\n    def _load_collations(self, conn):\n        for name, fn in self._collations.items():\n            conn.create_collation(name, fn)\n\n    def _load_functions(self, conn):\n        for name, (fn, n_params, deterministic) in self._functions.items():\n            kwargs = {'deterministic': deterministic} if deterministic else {}\n            conn.create_function(name, n_params, fn, **kwargs)\n\n    def _load_window_functions(self, conn):\n        for name, (klass, num_params) in self._window_functions.items():\n            conn.create_window_function(name, num_params, klass)\n\n    def register_aggregate(self, klass, name=None, num_params=-1):\n        self._aggregates[name or klass.__name__.lower()] = (klass, num_params)\n        if not self.is_closed():\n            self._load_aggregates(self.connection())\n\n    def aggregate(self, name=None, num_params=-1):\n        def decorator(klass):\n            self.register_aggregate(klass, name, num_params)\n            return klass\n        return decorator\n\n    def register_collation(self, fn, name=None):\n        name = name or fn.__name__\n        def _collation(*args):\n            expressions = args + (SQL('collate %s' % name),)\n            return NodeList(expressions)\n        fn.collation = _collation\n        self._collations[name] = fn\n        if not self.is_closed():\n            self._load_collations(self.connection())\n\n    def collation(self, name=None):\n        def decorator(fn):\n            self.register_collation(fn, name)\n            return fn\n        return decorator\n\n    def register_function(self, fn, name=None, num_params=-1,\n                          deterministic=None):\n        self._functions[name or fn.__name__] = (fn, num_params, deterministic)\n        if not self.is_closed():\n            self._load_functions(self.connection())\n\n    def func(self, name=None, num_params=-1, deterministic=None):\n        def decorator(fn):\n            self.register_function(fn, name, num_params, deterministic)\n            return fn\n        return decorator\n\n    def register_window_function(self, klass, name=None, num_params=-1):\n        name = name or klass.__name__.lower()\n        self._window_functions[name] = (klass, num_params)\n        if not self.is_closed():\n            self._load_window_functions(self.connection())\n\n    def window_function(self, name=None, num_params=-1):\n        def decorator(klass):\n            self.register_window_function(klass, name, num_params)\n            return klass\n        return decorator\n\n    def register_table_function(self, klass, name=None):\n        if name is not None:\n            klass.name = name\n        self._table_functions.append(klass)\n        if not self.is_closed():\n            klass.register(self.connection())\n\n    def table_function(self, name=None):\n        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass\n        return decorator\n\n    def unregister_aggregate(self, name):\n        del(self._aggregates[name])\n\n    def unregister_collation(self, name):\n        del(self._collations[name])\n\n    def unregister_function(self, name):\n        del(self._functions[name])\n\n    def unregister_window_function(self, name):\n        del(self._window_functions[name])\n\n    def unregister_table_function(self, name):\n        for idx, klass in enumerate(self._table_functions):\n            if klass.name == name:\n                break\n        else:\n            return False\n        self._table_functions.pop(idx)\n        return True\n\n    def _load_extensions(self, conn):\n        conn.enable_load_extension(True)\n        for extension in self._extensions:\n            conn.load_extension(extension)\n\n    def load_extension(self, extension):\n        self._extensions.add(extension)\n        if not self.is_closed():\n            conn = self.connection()\n            conn.enable_load_extension(True)\n            conn.load_extension(extension)\n\n    def unload_extension(self, extension):\n        self._extensions.remove(extension)\n\n    def attach(self, filename, name):\n        if name in self._attached:\n            if self._attached[name] == filename:\n                return False\n            raise OperationalError('schema \"%s\" already attached.' % name)\n\n        self._attached[name] = filename\n        if not self.is_closed():\n            self.execute_sql('ATTACH DATABASE \"%s\" AS \"%s\"' % (filename, name))\n        return True\n\n    def detach(self, name):\n        if name not in self._attached:\n            return False\n\n        del self._attached[name]\n        if not self.is_closed():\n            self.execute_sql('DETACH DATABASE \"%s\"' % name)\n        return True\n\n    def last_insert_id(self, cursor, query_type=None):\n        if not self.returning_clause:\n            return cursor.lastrowid\n        elif query_type == Insert.SIMPLE:\n            try:\n                return cursor[0][0]\n            except (IndexError, KeyError, TypeError):\n                pass\n        return cursor\n\n    def rows_affected(self, cursor):\n        try:\n            return cursor.rowcount\n        except AttributeError:\n            return cursor.cursor.rowcount  # This was a RETURNING query.\n\n    def begin(self, lock_type=None):\n        statement = 'BEGIN %s' % lock_type if lock_type else 'BEGIN'\n        self.execute_sql(statement)\n\n    def commit(self):\n        with __exception_wrapper__:\n            return self.execute_sql('COMMIT')\n\n    def rollback(self):\n        with __exception_wrapper__:\n            return self.execute_sql('ROLLBACK')\n\n    def get_tables(self, schema=None):\n        schema = schema or 'main'\n        cursor = self.execute_sql('SELECT name FROM \"%s\".sqlite_master WHERE '\n                                  'type=? ORDER BY name' % schema, ('table',))\n        return [row for row, in cursor.fetchall()]\n\n    def get_views(self, schema=None):\n        sql = ('SELECT name, sql FROM \"%s\".sqlite_master WHERE type=? '\n               'ORDER BY name') % (schema or 'main')\n        return [ViewMetadata(*row) for row in self.execute_sql(sql, ('view',))]\n\n    def get_indexes(self, table, schema=None):\n        schema = schema or 'main'\n        query = ('SELECT name, sql FROM \"%s\".sqlite_master '\n                 'WHERE tbl_name = ? AND type = ? ORDER BY name') % schema\n        cursor = self.execute_sql(query, (table, 'index'))\n        index_to_sql = dict(cursor.fetchall())\n\n        # Determine which indexes have a unique constraint.\n        unique_indexes = set()\n        cursor = self.execute_sql('PRAGMA \"%s\".index_list(\"%s\")' %\n                                  (schema, table))\n        for row in cursor.fetchall():\n            name = row[1]\n            is_unique = int(row[2]) == 1\n            if is_unique:\n                unique_indexes.add(name)\n\n        # Retrieve the indexed columns.\n        index_columns = {}\n        for index_name in sorted(index_to_sql):\n            cursor = self.execute_sql('PRAGMA \"%s\".index_info(\"%s\")' %\n                                      (schema, index_name))\n            index_columns[index_name] = [row[2] for row in cursor.fetchall()]\n\n        return [\n            IndexMetadata(\n                name,\n                index_to_sql[name],\n                index_columns[name],\n                name in unique_indexes,\n                table)\n            for name in sorted(index_to_sql)]\n\n    def get_columns(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".table_info(\"%s\")' %\n                                  (schema or 'main', table))\n        return [ColumnMetadata(r[1], r[2], not r[3], bool(r[5]), table, r[4])\n                for r in cursor.fetchall()]\n\n    def get_primary_keys(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".table_info(\"%s\")' %\n                                  (schema or 'main', table))\n        return [row[1] for row in filter(lambda r: r[-1], cursor.fetchall())]\n\n    def get_foreign_keys(self, table, schema=None):\n        cursor = self.execute_sql('PRAGMA \"%s\".foreign_key_list(\"%s\")' %\n                                  (schema or 'main', table))\n        return [ForeignKeyMetadata(row[3], row[2], row[4], table)\n                for row in cursor.fetchall()]\n\n    def get_binary_type(self):\n        return sqlite3.Binary\n\n    def conflict_statement(self, on_conflict, query):\n        action = on_conflict._action.lower() if on_conflict._action else ''\n        if action and action not in ('nothing', 'update'):\n            return SQL('INSERT OR %s' % on_conflict._action.upper())\n\n    def conflict_update(self, oc, query):\n        # Sqlite prior to 3.24.0 does not support Postgres-style upsert.\n        if self.server_version < (3, 24, 0) and \\\n           any((oc._preserve, oc._update, oc._where, oc._conflict_target,\n                oc._conflict_constraint)):\n            raise ValueError('SQLite does not support specifying which values '\n                             'to preserve or update.')\n\n        action = oc._action.lower() if oc._action else ''\n        if action and action not in ('nothing', 'update', ''):\n            return\n\n        if action == 'nothing':\n            return SQL('ON CONFLICT DO NOTHING')\n        elif not oc._update and not oc._preserve:\n            raise ValueError('If you are not performing any updates (or '\n                             'preserving any INSERTed values), then the '\n                             'conflict resolution action should be set to '\n                             '\"NOTHING\".')\n        elif oc._conflict_constraint:\n            raise ValueError('SQLite does not support specifying named '\n                             'constraints for conflict resolution.')\n        elif not oc._conflict_target:\n            raise ValueError('SQLite requires that a conflict target be '\n                             'specified when doing an upsert.')\n\n        return self._build_on_conflict_update(oc, query)\n\n    def extract_date(self, date_part, date_field):\n        return fn.date_part(date_part, date_field, python_value=int)\n\n    def truncate_date(self, date_part, date_field):\n        return fn.date_trunc(date_part, date_field,\n                             python_value=simple_date_time)\n\n    def to_timestamp(self, date_field):\n        return fn.strftime('%s', date_field).cast('integer')\n\n    def from_timestamp(self, date_field):\n        return fn.datetime(date_field, 'unixepoch')"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3775,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase.table_function",
      "span": [
        3775,
        3779
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": "    def table_function(self, name=None):\n        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass\n        return decorator"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3776,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase.table_function.decorator",
      "span": [
        3776,
        3778
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": "        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass"
    },
    {
      "path": "peewee.py",
      "version": "old",
      "line": 3793,
      "kind": "function",
      "qualname": "peewee.SqliteDatabase.unregister_table_function",
      "span": [
        3793,
        3800
      ],
      "reason": "diff_old_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": "    def unregister_table_function(self, name):\n        for idx, klass in enumerate(self._table_functions):\n            if klass.name == name:\n                break\n        else:\n            return False\n        self._table_functions.pop(idx)\n        return True"
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 26,
      "kind": "module",
      "qualname": "playhouse.cysqlite_ext",
      "span": null,
      "reason": "diff_new_line_outside_defs",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": null
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 60,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase.__init__",
      "span": [
        56,
        74
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def __init__(self, database, rank_functions=True, regexp_function=False,\n                 *args, **kwargs):\n        super(CySqliteDatabase, self).__init__(database, *args, **kwargs)\n\n        self._table_functions = []\n        self._commit_hook = None\n        self._rollback_hook = None\n        self._update_hook = None\n        self._authorizer = None\n        self._trace = None\n        self._progress = None\n\n        if rank_functions:\n            self.register_function(cysqlite.rank_bm25, 'fts_bm25')\n            self.register_function(cysqlite.rank_lucene, 'fts_lucene')\n            self.register_function(rank, 'fts_rank')\n\n        if regexp_function:\n            self.register_function(_sqlite_regexp, 'regexp', 2)",
      "old_code": "    def __init__(self, database, rank_functions=True, regexp_function=False,\n                 *args, **kwargs):\n        super(CySqliteDatabase, self).__init__(database, *args, **kwargs)\n\n        self._commit_hook = None\n        self._rollback_hook = None\n        self._update_hook = None\n        self._authorizer = None\n        self._trace = None\n        self._progress = None\n\n        if rank_functions:\n            self.register_function(cysqlite.rank_bm25, 'fts_bm25')\n            self.register_function(cysqlite.rank_lucene, 'fts_lucene')\n            self.register_function(rank, 'fts_rank')\n\n        if regexp_function:\n            self.register_function(_sqlite_regexp, 'regexp', 2)"
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 102,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase._add_conn_hooks",
      "span": [
        88,
        104
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def _add_conn_hooks(self, conn):\n        if self._commit_hook is not None:\n            conn.commit_hook(self._commit_hook)\n        if self._rollback_hook is not None:\n            conn.rollback_hook(self._rollback_hook)\n        if self._update_hook is not None:\n            conn.update_hook(self._update_hook)\n        if self._authorizer is not None:\n            conn.authorizer(self._authorizer)\n        if self._trace is not None:\n            conn.trace(*self._trace)\n        if self._progress is not None:\n            conn.progress(*self._progress)\n        super(CySqliteDatabase, self)._add_conn_hooks(conn)\n        if self._table_functions:\n            for table_function in self._table_functions:\n                table_function.register(conn)",
      "old_code": "    def _add_conn_hooks(self, conn):\n        if self._commit_hook is not None:\n            conn.commit_hook(self._commit_hook)\n        if self._rollback_hook is not None:\n            conn.rollback_hook(self._rollback_hook)\n        if self._update_hook is not None:\n            conn.update_hook(self._update_hook)\n        if self._authorizer is not None:\n            conn.authorizer(self._authorizer)\n        if self._trace is not None:\n            conn.trace(*self._trace)\n        if self._progress is not None:\n            conn.progress(*self._progress)\n        super(CySqliteDatabase, self)._add_conn_hooks(conn)"
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 130,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase.register_table_function",
      "span": [
        130,
        135
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def register_table_function(self, klass, name=None):\n        if name is not None:\n            klass.name = name\n        self._table_functions.append(klass)\n        if not self.is_closed():\n            klass.register(self.connection())",
      "old_code": null
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 136,
      "kind": "class",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase",
      "span": [
        55,
        265
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class CySqliteDatabase(SqliteDatabase):\n    def __init__(self, database, rank_functions=True, regexp_function=False,\n                 *args, **kwargs):\n        super(CySqliteDatabase, self).__init__(database, *args, **kwargs)\n\n        self._table_functions = []\n        self._commit_hook = None\n        self._rollback_hook = None\n        self._update_hook = None\n        self._authorizer = None\n        self._trace = None\n        self._progress = None\n\n        if rank_functions:\n            self.register_function(cysqlite.rank_bm25, 'fts_bm25')\n            self.register_function(cysqlite.rank_lucene, 'fts_lucene')\n            self.register_function(rank, 'fts_rank')\n\n        if regexp_function:\n            self.register_function(_sqlite_regexp, 'regexp', 2)\n\n    def _connect(self):\n        if cysqlite is None:\n            raise ImproperlyConfigured('cysqlite is not installed.')\n        conn = cysqlite.Connection(self.database, timeout=self._timeout,\n                                   extensions=True, **self.connect_params)\n        try:\n            self._add_conn_hooks(conn)\n        except Exception:\n            conn.close()\n            raise\n        return conn\n\n    def _add_conn_hooks(self, conn):\n        if self._commit_hook is not None:\n            conn.commit_hook(self._commit_hook)\n        if self._rollback_hook is not None:\n            conn.rollback_hook(self._rollback_hook)\n        if self._update_hook is not None:\n            conn.update_hook(self._update_hook)\n        if self._authorizer is not None:\n            conn.authorizer(self._authorizer)\n        if self._trace is not None:\n            conn.trace(*self._trace)\n        if self._progress is not None:\n            conn.progress(*self._progress)\n        super(CySqliteDatabase, self)._add_conn_hooks(conn)\n        if self._table_functions:\n            for table_function in self._table_functions:\n                table_function.register(conn)\n\n    def _set_pragmas(self, conn):\n        for pragma, value in self._pragmas:\n            conn.pragma(pragma, value)\n\n    def _attach_databases(self, conn):\n        for name, db in self._attached.items():\n            conn.attach(db, name)\n\n    def _load_aggregates(self, conn):\n        for name, (klass, num_params) in self._aggregates.items():\n            conn.create_aggregate(klass, name, num_params)\n\n    def _load_collations(self, conn):\n        for name, fn in self._collations.items():\n            conn.create_collation(fn, name)\n\n    def _load_functions(self, conn):\n        for name, (fn, num_params, deterministic) in self._functions.items():\n            conn.create_function(fn, name, num_params, deterministic)\n\n    def _load_window_functions(self, conn):\n        for name, (klass, num_params) in self._window_functions.items():\n            conn.create_window_function(klass, name, num_params)\n\n    def register_table_function(self, klass, name=None):\n        if name is not None:\n            klass.name = name\n        self._table_functions.append(klass)\n        if not self.is_closed():\n            klass.register(self.connection())\n\n    def unregister_table_function(self, name):\n        for idx, klass in enumerate(self._table_functions):\n            if klass.name == name:\n                break\n        else:\n            return False\n        self._table_functions.pop(idx)\n        return True\n\n    def table_function(self, name=None):\n        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass\n        return decorator\n\n    def on_commit(self, fn):\n        self._commit_hook = fn\n        if not self.is_closed():\n            self.connection().commit_hook(fn)\n        return fn\n\n    def on_rollback(self, fn):\n        self._rollback_hook = fn\n        if not self.is_closed():\n            self.connection().rollback_hook(fn)\n        return fn\n\n    def on_update(self, fn):\n        self._update_hook = fn\n        if not self.is_closed():\n            self.connection().update_hook(fn)\n        return fn\n\n    def authorizer(self, fn):\n        self._authorizer = fn\n        if not self.is_closed():\n            self.connection().authorizer(fn)\n        return fn\n\n    def trace(self, fn, mask=2):\n        if fn is None:\n            self._trace = None\n        else:\n            self._trace = (fn, mask)\n        if not self.is_closed():\n            args = (None,) if fn is None else self._trace\n            self.connection().authorizer(*args)\n        return fn\n\n    def progress(self, fn, n=1):\n        if fn is None:\n            self._progress = None\n        else:\n            self._progress = (fn, mask)\n        if not self.is_closed():\n            args = (None,) if fn is None else self._progress\n            self.connection().progress(*args)\n        return fn\n\n    def begin(self, lock_type='deferred'):\n        with __exception_wrapper__:\n            self.connection().begin(lock_type)\n\n    def commit(self):\n        with __exception_wrapper__:\n            self.connection().commit()\n\n    def rollback(self):\n        with __exception_wrapper__:\n            self.connection().rollback()\n\n    @property\n    def autocommit(self):\n        return self.connection().autocommit()\n\n    def blob_open(self, table, column, rowid, read_only=False, dbname=None):\n        return self.connection().blob_open(table, column, rowid, read_only,\n                                           db_name)\n\n    def backup(self, destination, pages=None, name=None, progress=None,\n               src_name=None):\n\n        if isinstance(destination, CySqliteDatabase):\n            conn = destination.connection()\n        elif isinstance(destination, cysqlite.Connection):\n            conn = destination\n        elif isinstance(destination, (str, Path)):\n            return self.backup_to_file(str(destination), pages, name,\n                                       progress, src_name)\n\n        return self.connection().backup(conn, pages, name, progress, src_name)\n\n    def backup_to_file(self, filename, pages=None, name=None, progress=None,\n                       src_name=None):\n        return self.connection().backup_to_file(filename, pages, name,\n                                                progress, src_name)\n\n    # Status properties.\n    memory_used = __status__(cysqlite.C_SQLITE_STATUS_MEMORY_USED)\n    malloc_size = __status__(cysqlite.C_SQLITE_STATUS_MALLOC_SIZE, True)\n    malloc_count = __status__(cysqlite.C_SQLITE_STATUS_MALLOC_COUNT)\n    pagecache_used = __status__(cysqlite.C_SQLITE_STATUS_PAGECACHE_USED)\n    pagecache_overflow = __status__(\n        cysqlite.C_SQLITE_STATUS_PAGECACHE_OVERFLOW)\n    pagecache_size = __status__(cysqlite.C_SQLITE_STATUS_PAGECACHE_SIZE, True)\n    scratch_used = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_USED)\n    scratch_overflow = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_OVERFLOW)\n    scratch_size = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_SIZE, True)\n\n    # Connection status properties.\n    lookaside_used = __dbstatus__(cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_USED)\n    lookaside_hit = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_HIT, True)\n    lookaside_miss = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_MISS_SIZE, True)\n    lookaside_miss_full = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_MISS_FULL, True)\n    cache_used = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_CACHE_USED, False, True)\n    schema_used = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_SCHEMA_USED, False, True)\n    statement_used = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_STMT_USED, False, True)\n    cache_hit = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_CACHE_HIT, False, True)\n    cache_miss = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_CACHE_MISS, False, True)\n    cache_write = __dbstatus__(\n        cysqlite.C_SQLITE_DBSTATUS_CACHE_WRITE, False, True)",
      "old_code": "class CySqliteDatabase(SqliteDatabase):\n    def __init__(self, database, rank_functions=True, regexp_function=False,\n                 *args, **kwargs):\n        super(CySqliteDatabase, self).__init__(database, *args, **kwargs)\n\n        self._commit_hook = None\n        self._rollback_hook = None\n        self._update_hook = None\n        self._authorizer = None\n        self._trace = None\n        self._progress = None\n\n        if rank_functions:\n            self.register_function(cysqlite.rank_bm25, 'fts_bm25')\n            self.register_function(cysqlite.rank_lucene, 'fts_lucene')\n            self.register_function(rank, 'fts_rank')\n\n        if regexp_function:\n            self.register_function(_sqlite_regexp, 'regexp', 2)\n\n    def _connect(self):\n        if cysqlite is None:\n            raise ImproperlyConfigured('cysqlite is not installed.')\n        conn = cysqlite.Connection(self.database, timeout=self._timeout,\n                                   extensions=True, **self.connect_params)\n        try:\n            self._add_conn_hooks(conn)\n        except Exception:\n            conn.close()\n            raise\n        return conn\n\n    def _add_conn_hooks(self, conn):\n        if self._commit_hook is not None:\n            conn.commit_hook(self._commit_hook)\n        if self._rollback_hook is not None:\n            conn.rollback_hook(self._rollback_hook)\n        if self._update_hook is not None:\n            conn.update_hook(self._update_hook)\n        if self._authorizer is not None:\n            conn.authorizer(self._authorizer)\n        if self._trace is not None:\n            conn.trace(*self._trace)\n        if self._progress is not None:\n            conn.progress(*self._progress)\n        super(CySqliteDatabase, self)._add_conn_hooks(conn)\n\n    def _set_pragmas(self, conn):\n        for pragma, value in self._pragmas:\n            conn.pragma(pragma, value)\n\n    def _attach_databases(self, conn):\n        for name, db in self._attached.items():\n            conn.attach(db, name)\n\n    def _load_aggregates(self, conn):\n        for name, (klass, num_params) in self._aggregates.items():\n            conn.create_aggregate(klass, name, num_params)\n\n    def _load_collations(self, conn):\n        for name, fn in self._collations.items():\n            conn.create_collation(fn, name)\n\n    def _load_functions(self, conn):\n        for name, (fn, num_params, deterministic) in self._functions.items():\n            conn.create_function(fn, name, num_params, deterministic)\n\n    def _load_window_functions(self, conn):\n        for name, (klass, num_params) in self._window_functions.items():\n            conn.create_window_function(klass, name, num_params)\n\n    def on_commit(self, fn):\n        self._commit_hook = fn\n        if not self.is_closed():\n            self.connection().commit_hook(fn)\n        return fn\n\n    def on_rollback(self, fn):\n        self._rollback_hook = fn\n        if not self.is_closed():\n            self.connection().rollback_hook(fn)\n        return fn\n\n    def on_update(self, fn):\n        self._update_hook = fn\n        if not self.is_closed():\n            self.connection().update_hook(fn)\n        return fn\n\n    def authorizer(self, fn):\n        self._authorizer = fn\n        if not self.is_closed():\n            self.connection().authorizer(fn)\n        return fn\n\n    def trace(self, fn, mask=2):\n        if fn is None:\n            self._trace = None\n        else:\n            self._trace = (fn, mask)\n        if not self.is_closed():\n            args = (None,) if fn is None else self._trace\n            self.connection().authorizer(*args)\n        return fn\n\n    def progress(self, fn, n=1):\n        if fn is None:\n            self._progress = None\n        else:\n            self._progress = (fn, mask)\n        if not self.is_closed():\n            args = (None,) if fn is None else self._progress\n            self.connection().progress(*args)\n        return fn\n\n    def begin(self, lock_type='deferred'):\n        with __exception_wrapper__:\n            self.connection().begin(lock_type)\n\n    def commit(self):\n        with __exception_wrapper__:\n            self.connection().commit()\n\n    def rollback(self):\n        with __exception_wrapper__:\n            self.connection().rollback()\n\n    @property\n    def autocommit(self):\n        return self.connection().autocommit()\n\n    def blob_open(self, table, column, rowid, read_only=False, dbname=None):\n        return self.connection().blob_open(table, column, rowid, read_only,\n                                           db_name)\n\n    def backup(self, destination, pages=None, name=None, progress=None,\n               src_name=None):\n\n        if isinstance(destination, CySqliteDatabase):\n            conn = destination.connection()\n        elif isinstance(destination, cysqlite.Connection):\n            conn = destination\n        elif isinstance(destination, (str, Path)):\n            return self.backup_to_file(str(destination), pages, name,\n                                       progress, src_name)\n\n        return self.connection().backup(conn, pages, name, progress, src_name)\n\n    def backup_to_file(self, filename, pages=None, name=None, progress=None,\n                       src_name=None):\n        return self.connection().backup_to_file(filename, pages, name,\n                                                progress, src_name)\n\n    # Status properties.\n    if cysqlite is not None:\n        memory_used = __status__(cysqlite.C_SQLITE_STATUS_MEMORY_USED)\n        malloc_size = __status__(cysqlite.C_SQLITE_STATUS_MALLOC_SIZE, True)\n        malloc_count = __status__(cysqlite.C_SQLITE_STATUS_MALLOC_COUNT)\n        pagecache_used = __status__(cysqlite.C_SQLITE_STATUS_PAGECACHE_USED)\n        pagecache_overflow = __status__(\n            cysqlite.C_SQLITE_STATUS_PAGECACHE_OVERFLOW)\n        pagecache_size = __status__(cysqlite.C_SQLITE_STATUS_PAGECACHE_SIZE, True)\n        scratch_used = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_USED)\n        scratch_overflow = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_OVERFLOW)\n        scratch_size = __status__(cysqlite.C_SQLITE_STATUS_SCRATCH_SIZE, True)\n\n        # Connection status properties.\n        lookaside_used = __dbstatus__(cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_USED)\n        lookaside_hit = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_HIT, True)\n        lookaside_miss = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_MISS_SIZE, True)\n        lookaside_miss_full = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_LOOKASIDE_MISS_FULL, True)\n        cache_used = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_CACHE_USED, False, True)\n        schema_used = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_SCHEMA_USED, False, True)\n        statement_used = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_STMT_USED, False, True)\n        cache_hit = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_CACHE_HIT, False, True)\n        cache_miss = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_CACHE_MISS, False, True)\n        cache_write = __dbstatus__(\n            cysqlite.C_SQLITE_DBSTATUS_CACHE_WRITE, False, True)"
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 137,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase.unregister_table_function",
      "span": [
        137,
        144
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def unregister_table_function(self, name):\n        for idx, klass in enumerate(self._table_functions):\n            if klass.name == name:\n                break\n        else:\n            return False\n        self._table_functions.pop(idx)\n        return True",
      "old_code": null
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 146,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase.table_function",
      "span": [
        146,
        150
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def table_function(self, name=None):\n        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass\n        return decorator",
      "old_code": null
    },
    {
      "path": "playhouse/cysqlite_ext.py",
      "version": "new",
      "line": 147,
      "kind": "function",
      "qualname": "playhouse.cysqlite_ext.CySqliteDatabase.table_function.decorator",
      "span": [
        147,
        149
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "        def decorator(klass):\n            self.register_table_function(klass, name)\n            return klass",
      "old_code": null
    },
    {
      "path": "tests/base.py",
      "version": "new",
      "line": 20,
      "kind": "module",
      "qualname": "tests.base",
      "span": null,
      "reason": "diff_new_line_outside_defs",
      "is_test": true,
      "seed_type": "test_change",
      "new_code": null,
      "old_code": null
    },
    {
      "path": "tests/base.py",
      "version": "new",
      "line": 42,
      "kind": "function",
      "qualname": "tests.base.db_loader",
      "span": [
        29,
        54
      ],
      "reason": "diff_new_line_in_def",
      "is_test": true,
      "seed_type": "test_change",
      "new_code": "def db_loader(engine, name='peewee_test', db_class=None, **params):\n    if db_class is None:\n        engine_aliases = {\n            SqliteDatabase: ['sqlite', 'sqlite3'],\n            CySqliteDatabase: ['cysqlite'],\n            MySQLDatabase: ['mysql'],\n            PostgresqlDatabase: ['postgres', 'postgresql'],\n            Psycopg3Database: ['psycopg3'],\n            MySQLConnectorDatabase: ['mysqlconnector'],\n            MariaDBConnectorDatabase: ['mariadb', 'maridbconnector'],\n            CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n        }\n        engine_map = dict((alias, db) for db, aliases in engine_aliases.items()\n                          for alias in aliases if db is not None)\n        if engine.lower() not in engine_map:\n            raise Exception('Unsupported engine: %s.' % engine)\n        db_class = engine_map[engine.lower()]\n    if issubclass(db_class, SqliteDatabase) and not name.endswith('.db'):\n        name = '%s.db' % name if name != ':memory:' else name\n    elif issubclass(db_class, MySQLDatabase):\n        params.update(MYSQL_PARAMS)\n    elif issubclass(db_class, CockroachDatabase):\n        params.update(CRDB_PARAMS)\n    elif issubclass(db_class, PostgresqlDatabase):\n        params.update(PSQL_PARAMS)\n    return db_class(name, **params)",
      "old_code": "def db_loader(engine, name='peewee_test', db_class=None, **params):\n    if db_class is None:\n        engine_aliases = {\n            SqliteDatabase: ['sqlite', 'sqlite3'],\n            CySqliteDatabase: ['cysqlite'],\n            MySQLDatabase: ['mysql'],\n            PostgresqlDatabase: ['postgres', 'postgresql'],\n            Psycopg3Database: ['psycopg3'],\n            MySQLConnectorDatabase: ['mysqlconnector'],\n            MariaDBConnectorDatabase: ['mariadb', 'maridbconnector'],\n            CockroachDatabase: ['cockroach', 'cockroachdb', 'crdb'],\n        }\n        engine_map = dict((alias, db) for db, aliases in engine_aliases.items()\n                          for alias in aliases)\n        if engine.lower() not in engine_map:\n            raise Exception('Unsupported engine: %s.' % engine)\n        db_class = engine_map[engine.lower()]\n    if issubclass(db_class, SqliteDatabase) and not name.endswith('.db'):\n        name = '%s.db' % name if name != ':memory:' else name\n    elif issubclass(db_class, MySQLDatabase):\n        params.update(MYSQL_PARAMS)\n    elif issubclass(db_class, CockroachDatabase):\n        params.update(CRDB_PARAMS)\n    elif issubclass(db_class, PostgresqlDatabase):\n        params.update(PSQL_PARAMS)\n    return db_class(name, **params)"
    }
  ],
  "generated_at": "2026-02-10T15:01:10"
}