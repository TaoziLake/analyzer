{
  "commit": "58c5ac8",
  "parent": "6ea3ef87be2232585015849a007fecd3b708f9fb",
  "repo": "d:\\locbench\\black",
  "num_files_in_diff": 9,
  "num_py_files_in_diff": 8,
  "num_seeds": 12,
  "seeds": [
    {
      "path": "scripts/release.py",
      "version": "new",
      "line": 71,
      "kind": "class",
      "qualname": "scripts.release.NoGitTagsError",
      "span": [
        71,
        71
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "class NoGitTagsError(Exception): ...",
      "old_code": "class NoGitTagsError(Exception): ...  # noqa: E701,E761"
    },
    {
      "path": "scripts/release_tests.py",
      "version": "new",
      "line": 16,
      "kind": "function",
      "qualname": "scripts.release_tests.FakeDateTime.today",
      "span": [
        16,
        17
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def today(*args: Any, **kwargs: Any) -> \"FakeDateTime\":  # noqa: B902\n        return FakeDateTime()",
      "old_code": "    def today(*args: Any, **kwargs: Any) -> \"FakeDateTime\":  # noqa\n        return FakeDateTime()"
    },
    {
      "path": "scripts/release_tests.py",
      "version": "new",
      "line": 20,
      "kind": "function",
      "qualname": "scripts.release_tests.FakeDateTime.strftime",
      "span": [
        20,
        21
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def strftime(*args: Any, **kwargs: Any) -> str:  # noqa: B902\n        return \"69.01\"",
      "old_code": "    def strftime(*args: Any, **kwargs: Any) -> str:  # noqa\n        return \"69.01\""
    },
    {
      "path": "src/black/__init__.py",
      "version": "new",
      "line": 516,
      "kind": "function",
      "qualname": "src.black.__init__.main",
      "span": [
        516,
        730
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def main(\n    ctx: click.Context,\n    code: str | None,\n    line_length: int,\n    target_version: list[TargetVersion],\n    check: bool,\n    diff: bool,\n    line_ranges: Sequence[str],\n    color: bool,\n    fast: bool,\n    pyi: bool,\n    ipynb: bool,\n    python_cell_magics: Sequence[str],\n    skip_source_first_line: bool,\n    skip_string_normalization: bool,\n    skip_magic_trailing_comma: bool,\n    preview: bool,\n    unstable: bool,\n    enable_unstable_feature: list[Preview],\n    quiet: bool,\n    verbose: bool,\n    required_version: str | None,\n    include: Pattern[str],\n    exclude: Pattern[str] | None,\n    extend_exclude: Pattern[str] | None,\n    force_exclude: Pattern[str] | None,\n    stdin_filename: str | None,\n    workers: int | None,\n    src: tuple[str, ...],\n    config: str | None,\n    no_cache: bool,\n) -> None:\n    \"\"\"The uncompromising code formatter.\"\"\"\n    ctx.ensure_object(dict)\n\n    assert sys.version_info >= (3, 10), \"Black requires Python 3.10+\"\n    if sys.version_info[:3] == (3, 12, 5):\n        out(\n            \"Python 3.12.5 has a memory safety issue that can cause Black's \"\n            \"AST safety checks to fail. \"\n            \"Please upgrade to Python 3.12.6 or downgrade to Python 3.12.4\"\n        )\n        ctx.exit(1)\n\n    if src and code is not None:\n        out(\n            main.get_usage(ctx)\n            + \"\\n\\n'SRC' and 'code' cannot be passed simultaneously.\"\n        )\n        ctx.exit(1)\n    if not src and code is None:\n        out(main.get_usage(ctx) + \"\\n\\nOne of 'SRC' or 'code' is required.\")\n        ctx.exit(1)\n\n    # It doesn't do anything if --unstable is also passed, so just allow it.\n    if enable_unstable_feature and not (preview or unstable):\n        out(\n            main.get_usage(ctx)\n            + \"\\n\\n'--enable-unstable-feature' requires '--preview'.\"\n        )\n        ctx.exit(1)\n\n    root, method = (\n        find_project_root(src, stdin_filename) if code is None else (None, None)\n    )\n    ctx.obj[\"root\"] = root\n\n    if verbose:\n        if root:\n            out(\n                f\"Identified `{root}` as project root containing a {method}.\",\n                fg=\"blue\",\n            )\n\n        if config:\n            config_source = ctx.get_parameter_source(\"config\")\n            user_level_config = str(find_user_pyproject_toml())\n            if config == user_level_config:\n                out(\n                    \"Using configuration from user-level config at \"\n                    f\"'{user_level_config}'.\",\n                    fg=\"blue\",\n                )\n            elif config_source in (\n                ParameterSource.DEFAULT,\n                ParameterSource.DEFAULT_MAP,\n            ):\n                out(\"Using configuration from project root.\", fg=\"blue\")\n            else:\n                out(f\"Using configuration in '{config}'.\", fg=\"blue\")\n            if ctx.default_map:\n                for param, value in ctx.default_map.items():\n                    out(f\"{param}: {value}\")\n\n    error_msg = \"Oh no! ğŸ’¥ ğŸ’” ğŸ’¥\"\n    if (\n        required_version\n        and required_version != __version__\n        and required_version != __version__.split(\".\")[0]\n    ):\n        err(\n            f\"{error_msg} The required version `{required_version}` does not match\"\n            f\" the running version `{__version__}`!\"\n        )\n        ctx.exit(1)\n    if ipynb and pyi:\n        err(\"Cannot pass both `pyi` and `ipynb` flags!\")\n        ctx.exit(1)\n\n    write_back = WriteBack.from_configuration(check=check, diff=diff, color=color)\n    if target_version:\n        versions = set(target_version)\n    else:\n        # We'll autodetect later.\n        versions = set()\n    mode = Mode(\n        target_versions=versions,\n        line_length=line_length,\n        is_pyi=pyi,\n        is_ipynb=ipynb,\n        skip_source_first_line=skip_source_first_line,\n        string_normalization=not skip_string_normalization,\n        magic_trailing_comma=not skip_magic_trailing_comma,\n        preview=preview,\n        unstable=unstable,\n        python_cell_magics=set(python_cell_magics),\n        enabled_features=set(enable_unstable_feature),\n    )\n\n    lines: list[tuple[int, int]] = []\n    if line_ranges:\n        if ipynb:\n            err(\"Cannot use --line-ranges with ipynb files.\")\n            ctx.exit(1)\n\n        try:\n            lines = parse_line_ranges(line_ranges)\n        except ValueError as e:\n            err(str(e))\n            ctx.exit(1)\n\n    if code is not None:\n        # Run in quiet mode by default with -c; the extra output isn't useful.\n        # You can still pass -v to get verbose output.\n        quiet = True\n\n    report = Report(check=check, diff=diff, quiet=quiet, verbose=verbose)\n\n    if code is not None:\n        reformat_code(\n            content=code,\n            fast=fast,\n            write_back=write_back,\n            mode=mode,\n            report=report,\n            lines=lines,\n        )\n    else:\n        assert root is not None  # root is only None if code is not None\n        try:\n            sources = get_sources(\n                root=root,\n                src=src,\n                quiet=quiet,\n                verbose=verbose,\n                include=include,\n                exclude=exclude,\n                extend_exclude=extend_exclude,\n                force_exclude=force_exclude,\n                report=report,\n                stdin_filename=stdin_filename,\n            )\n        except GitWildMatchPatternError:\n            ctx.exit(1)\n\n        if not sources:\n            if verbose or not quiet:\n                out(\"No Python files are present to be formatted. Nothing to do ğŸ˜´\")\n            if \"-\" in src:\n                sys.stdout.write(sys.stdin.read())\n            ctx.exit(0)\n\n        if len(sources) == 1:\n            reformat_one(\n                src=sources.pop(),\n                fast=fast,\n                write_back=write_back,\n                mode=mode,\n                report=report,\n                lines=lines,\n                no_cache=no_cache,\n            )\n        else:\n            from black.concurrency import reformat_many\n\n            if lines:\n                err(\"Cannot use --line-ranges to format multiple files.\")\n                ctx.exit(1)\n            reformat_many(\n                sources=sources,\n                fast=fast,\n                write_back=write_back,\n                mode=mode,\n                report=report,\n                workers=workers,\n                no_cache=no_cache,\n            )\n\n    if verbose or not quiet:\n        if code is None and (verbose or report.change_count or report.failure_count):\n            out()\n        out(error_msg if report.return_code else \"All done! âœ¨ ğŸ° âœ¨\")\n        if code is None:\n            click.echo(str(report), err=True)\n    ctx.exit(report.return_code)",
      "old_code": "def main(  # noqa: C901\n    ctx: click.Context,\n    code: str | None,\n    line_length: int,\n    target_version: list[TargetVersion],\n    check: bool,\n    diff: bool,\n    line_ranges: Sequence[str],\n    color: bool,\n    fast: bool,\n    pyi: bool,\n    ipynb: bool,\n    python_cell_magics: Sequence[str],\n    skip_source_first_line: bool,\n    skip_string_normalization: bool,\n    skip_magic_trailing_comma: bool,\n    preview: bool,\n    unstable: bool,\n    enable_unstable_feature: list[Preview],\n    quiet: bool,\n    verbose: bool,\n    required_version: str | None,\n    include: Pattern[str],\n    exclude: Pattern[str] | None,\n    extend_exclude: Pattern[str] | None,\n    force_exclude: Pattern[str] | None,\n    stdin_filename: str | None,\n    workers: int | None,\n    src: tuple[str, ...],\n    config: str | None,\n    no_cache: bool,\n) -> None:\n    \"\"\"The uncompromising code formatter.\"\"\"\n    ctx.ensure_object(dict)\n\n    assert sys.version_info >= (3, 10), \"Black requires Python 3.10+\"\n    if sys.version_info[:3] == (3, 12, 5):\n        out(\n            \"Python 3.12.5 has a memory safety issue that can cause Black's \"\n            \"AST safety checks to fail. \"\n            \"Please upgrade to Python 3.12.6 or downgrade to Python 3.12.4\"\n        )\n        ctx.exit(1)\n\n    if src and code is not None:\n        out(\n            main.get_usage(ctx)\n            + \"\\n\\n'SRC' and 'code' cannot be passed simultaneously.\"\n        )\n        ctx.exit(1)\n    if not src and code is None:\n        out(main.get_usage(ctx) + \"\\n\\nOne of 'SRC' or 'code' is required.\")\n        ctx.exit(1)\n\n    # It doesn't do anything if --unstable is also passed, so just allow it.\n    if enable_unstable_feature and not (preview or unstable):\n        out(\n            main.get_usage(ctx)\n            + \"\\n\\n'--enable-unstable-feature' requires '--preview'.\"\n        )\n        ctx.exit(1)\n\n    root, method = (\n        find_project_root(src, stdin_filename) if code is None else (None, None)\n    )\n    ctx.obj[\"root\"] = root\n\n    if verbose:\n        if root:\n            out(\n                f\"Identified `{root}` as project root containing a {method}.\",\n                fg=\"blue\",\n            )\n\n        if config:\n            config_source = ctx.get_parameter_source(\"config\")\n            user_level_config = str(find_user_pyproject_toml())\n            if config == user_level_config:\n                out(\n                    \"Using configuration from user-level config at \"\n                    f\"'{user_level_config}'.\",\n                    fg=\"blue\",\n                )\n            elif config_source in (\n                ParameterSource.DEFAULT,\n                ParameterSource.DEFAULT_MAP,\n            ):\n                out(\"Using configuration from project root.\", fg=\"blue\")\n            else:\n                out(f\"Using configuration in '{config}'.\", fg=\"blue\")\n            if ctx.default_map:\n                for param, value in ctx.default_map.items():\n                    out(f\"{param}: {value}\")\n\n    error_msg = \"Oh no! ğŸ’¥ ğŸ’” ğŸ’¥\"\n    if (\n        required_version\n        and required_version != __version__\n        and required_version != __version__.split(\".\")[0]\n    ):\n        err(\n            f\"{error_msg} The required version `{required_version}` does not match\"\n            f\" the running version `{__version__}`!\"\n        )\n        ctx.exit(1)\n    if ipynb and pyi:\n        err(\"Cannot pass both `pyi` and `ipynb` flags!\")\n        ctx.exit(1)\n\n    write_back = WriteBack.from_configuration(check=check, diff=diff, color=color)\n    if target_version:\n        versions = set(target_version)\n    else:\n        # We'll autodetect later.\n        versions = set()\n    mode = Mode(\n        target_versions=versions,\n        line_length=line_length,\n        is_pyi=pyi,\n        is_ipynb=ipynb,\n        skip_source_first_line=skip_source_first_line,\n        string_normalization=not skip_string_normalization,\n        magic_trailing_comma=not skip_magic_trailing_comma,\n        preview=preview,\n        unstable=unstable,\n        python_cell_magics=set(python_cell_magics),\n        enabled_features=set(enable_unstable_feature),\n    )\n\n    lines: list[tuple[int, int]] = []\n    if line_ranges:\n        if ipynb:\n            err(\"Cannot use --line-ranges with ipynb files.\")\n            ctx.exit(1)\n\n        try:\n            lines = parse_line_ranges(line_ranges)\n        except ValueError as e:\n            err(str(e))\n            ctx.exit(1)\n\n    if code is not None:\n        # Run in quiet mode by default with -c; the extra output isn't useful.\n        # You can still pass -v to get verbose output.\n        quiet = True\n\n    report = Report(check=check, diff=diff, quiet=quiet, verbose=verbose)\n\n    if code is not None:\n        reformat_code(\n            content=code,\n            fast=fast,\n            write_back=write_back,\n            mode=mode,\n            report=report,\n            lines=lines,\n        )\n    else:\n        assert root is not None  # root is only None if code is not None\n        try:\n            sources = get_sources(\n                root=root,\n                src=src,\n                quiet=quiet,\n                verbose=verbose,\n                include=include,\n                exclude=exclude,\n                extend_exclude=extend_exclude,\n                force_exclude=force_exclude,\n                report=report,\n                stdin_filename=stdin_filename,\n            )\n        except GitWildMatchPatternError:\n            ctx.exit(1)\n\n        if not sources:\n            if verbose or not quiet:\n                out(\"No Python files are present to be formatted. Nothing to do ğŸ˜´\")\n            if \"-\" in src:\n                sys.stdout.write(sys.stdin.read())\n            ctx.exit(0)\n\n        if len(sources) == 1:\n            reformat_one(\n                src=sources.pop(),\n                fast=fast,\n                write_back=write_back,\n                mode=mode,\n                report=report,\n                lines=lines,\n                no_cache=no_cache,\n            )\n        else:\n            from black.concurrency import reformat_many\n\n            if lines:\n                err(\"Cannot use --line-ranges to format multiple files.\")\n                ctx.exit(1)\n            reformat_many(\n                sources=sources,\n                fast=fast,\n                write_back=write_back,\n                mode=mode,\n                report=report,\n                workers=workers,\n                no_cache=no_cache,\n            )\n\n    if verbose or not quiet:\n        if code is None and (verbose or report.change_count or report.failure_count):\n            out()\n        out(error_msg if report.return_code else \"All done! âœ¨ ğŸ° âœ¨\")\n        if code is None:\n            click.echo(str(report), err=True)\n    ctx.exit(report.return_code)"
    },
    {
      "path": "src/black/__init__.py",
      "version": "new",
      "line": 1336,
      "kind": "function",
      "qualname": "src.black.__init__.get_features_used",
      "span": [
        1336,
        1495
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def get_features_used(\n    node: Node, *, future_imports: set[str] | None = None\n) -> set[Feature]:\n    \"\"\"Return a set of (relatively) new Python features used in this file.\n\n    Currently looking for:\n    - f-strings;\n    - self-documenting expressions in f-strings (f\"{x=}\");\n    - underscores in numeric literals;\n    - trailing commas after * or ** in function signatures and calls;\n    - positional only arguments in function signatures and lambdas;\n    - assignment expression;\n    - relaxed decorator syntax;\n    - usage of __future__ flags (annotations);\n    - print / exec statements;\n    - parenthesized context managers;\n    - match statements;\n    - except* clause;\n    - variadic generics;\n    \"\"\"\n    features: set[Feature] = set()\n    if future_imports:\n        features |= {\n            FUTURE_FLAG_TO_FEATURE[future_import]\n            for future_import in future_imports\n            if future_import in FUTURE_FLAG_TO_FEATURE\n        }\n\n    for n in node.pre_order():\n        if n.type == token.FSTRING_START:\n            features.add(Feature.F_STRINGS)\n        elif n.type == token.TSTRING_START:\n            features.add(Feature.T_STRINGS)\n        elif (\n            n.type == token.RBRACE\n            and n.parent is not None\n            and any(child.type == token.EQUAL for child in n.parent.children)\n        ):\n            features.add(Feature.DEBUG_F_STRINGS)\n\n        elif is_number_token(n):\n            if \"_\" in n.value:\n                features.add(Feature.NUMERIC_UNDERSCORES)\n\n        elif n.type == token.SLASH:\n            if n.parent and n.parent.type in {\n                syms.typedargslist,\n                syms.arglist,\n                syms.varargslist,\n            }:\n                features.add(Feature.POS_ONLY_ARGUMENTS)\n\n        elif n.type == token.COLONEQUAL:\n            features.add(Feature.ASSIGNMENT_EXPRESSIONS)\n\n        elif n.type == syms.decorator:\n            if len(n.children) > 1 and not is_simple_decorator_expression(\n                n.children[1]\n            ):\n                features.add(Feature.RELAXED_DECORATORS)\n\n        elif (\n            n.type in {syms.typedargslist, syms.arglist}\n            and n.children\n            and n.children[-1].type == token.COMMA\n        ):\n            if n.type == syms.typedargslist:\n                feature = Feature.TRAILING_COMMA_IN_DEF\n            else:\n                feature = Feature.TRAILING_COMMA_IN_CALL\n\n            for ch in n.children:\n                if ch.type in STARS:\n                    features.add(feature)\n\n                if ch.type == syms.argument:\n                    for argch in ch.children:\n                        if argch.type in STARS:\n                            features.add(feature)\n\n        elif (\n            n.type in {syms.return_stmt, syms.yield_expr}\n            and len(n.children) >= 2\n            and n.children[1].type == syms.testlist_star_expr\n            and any(child.type == syms.star_expr for child in n.children[1].children)\n        ):\n            features.add(Feature.UNPACKING_ON_FLOW)\n\n        elif (\n            n.type == syms.annassign\n            and len(n.children) >= 4\n            and n.children[3].type == syms.testlist_star_expr\n        ):\n            features.add(Feature.ANN_ASSIGN_EXTENDED_RHS)\n\n        elif (\n            n.type == syms.with_stmt\n            and len(n.children) > 2\n            and n.children[1].type == syms.atom\n        ):\n            atom_children = n.children[1].children\n            if (\n                len(atom_children) == 3\n                and atom_children[0].type == token.LPAR\n                and _contains_asexpr(atom_children[1])\n                and atom_children[2].type == token.RPAR\n            ):\n                features.add(Feature.PARENTHESIZED_CONTEXT_MANAGERS)\n\n        elif n.type == syms.match_stmt:\n            features.add(Feature.PATTERN_MATCHING)\n\n        elif n.type in {syms.subscriptlist, syms.trailer} and any(\n            child.type == syms.star_expr for child in n.children\n        ):\n            features.add(Feature.VARIADIC_GENERICS)\n\n        elif (\n            n.type == syms.tname_star\n            and len(n.children) == 3\n            and n.children[2].type == syms.star_expr\n        ):\n            features.add(Feature.VARIADIC_GENERICS)\n\n        elif n.type in (syms.type_stmt, syms.typeparams):\n            features.add(Feature.TYPE_PARAMS)\n\n        elif (\n            n.type in (syms.typevartuple, syms.paramspec, syms.typevar)\n            and n.children[-2].type == token.EQUAL\n        ):\n            features.add(Feature.TYPE_PARAM_DEFAULTS)\n\n        elif (\n            n.type == syms.except_clause\n            and len(n.children) >= 2\n            and (\n                n.children[1].type == token.STAR or n.children[1].type == syms.testlist\n            )\n        ):\n            is_star_except = n.children[1].type == token.STAR\n\n            if is_star_except:\n                features.add(Feature.EXCEPT_STAR)\n\n            # Presence of except* pushes as clause 1 index back\n            has_as_clause = (\n                len(n.children) >= is_star_except + 3\n                and n.children[is_star_except + 2].type == token.NAME\n                and n.children[is_star_except + 2].value == \"as\"  # type: ignore\n            )\n\n            # If there's no 'as' clause and the except expression is a testlist.\n            if not has_as_clause and (\n                (is_star_except and n.children[2].type == syms.testlist)\n                or (not is_star_except and n.children[1].type == syms.testlist)\n            ):\n                features.add(Feature.UNPARENTHESIZED_EXCEPT_TYPES)\n\n    return features",
      "old_code": "def get_features_used(  # noqa: C901\n    node: Node, *, future_imports: set[str] | None = None\n) -> set[Feature]:\n    \"\"\"Return a set of (relatively) new Python features used in this file.\n\n    Currently looking for:\n    - f-strings;\n    - self-documenting expressions in f-strings (f\"{x=}\");\n    - underscores in numeric literals;\n    - trailing commas after * or ** in function signatures and calls;\n    - positional only arguments in function signatures and lambdas;\n    - assignment expression;\n    - relaxed decorator syntax;\n    - usage of __future__ flags (annotations);\n    - print / exec statements;\n    - parenthesized context managers;\n    - match statements;\n    - except* clause;\n    - variadic generics;\n    \"\"\"\n    features: set[Feature] = set()\n    if future_imports:\n        features |= {\n            FUTURE_FLAG_TO_FEATURE[future_import]\n            for future_import in future_imports\n            if future_import in FUTURE_FLAG_TO_FEATURE\n        }\n\n    for n in node.pre_order():\n        if n.type == token.FSTRING_START:\n            features.add(Feature.F_STRINGS)\n        elif n.type == token.TSTRING_START:\n            features.add(Feature.T_STRINGS)\n        elif (\n            n.type == token.RBRACE\n            and n.parent is not None\n            and any(child.type == token.EQUAL for child in n.parent.children)\n        ):\n            features.add(Feature.DEBUG_F_STRINGS)\n\n        elif is_number_token(n):\n            if \"_\" in n.value:\n                features.add(Feature.NUMERIC_UNDERSCORES)\n\n        elif n.type == token.SLASH:\n            if n.parent and n.parent.type in {\n                syms.typedargslist,\n                syms.arglist,\n                syms.varargslist,\n            }:\n                features.add(Feature.POS_ONLY_ARGUMENTS)\n\n        elif n.type == token.COLONEQUAL:\n            features.add(Feature.ASSIGNMENT_EXPRESSIONS)\n\n        elif n.type == syms.decorator:\n            if len(n.children) > 1 and not is_simple_decorator_expression(\n                n.children[1]\n            ):\n                features.add(Feature.RELAXED_DECORATORS)\n\n        elif (\n            n.type in {syms.typedargslist, syms.arglist}\n            and n.children\n            and n.children[-1].type == token.COMMA\n        ):\n            if n.type == syms.typedargslist:\n                feature = Feature.TRAILING_COMMA_IN_DEF\n            else:\n                feature = Feature.TRAILING_COMMA_IN_CALL\n\n            for ch in n.children:\n                if ch.type in STARS:\n                    features.add(feature)\n\n                if ch.type == syms.argument:\n                    for argch in ch.children:\n                        if argch.type in STARS:\n                            features.add(feature)\n\n        elif (\n            n.type in {syms.return_stmt, syms.yield_expr}\n            and len(n.children) >= 2\n            and n.children[1].type == syms.testlist_star_expr\n            and any(child.type == syms.star_expr for child in n.children[1].children)\n        ):\n            features.add(Feature.UNPACKING_ON_FLOW)\n\n        elif (\n            n.type == syms.annassign\n            and len(n.children) >= 4\n            and n.children[3].type == syms.testlist_star_expr\n        ):\n            features.add(Feature.ANN_ASSIGN_EXTENDED_RHS)\n\n        elif (\n            n.type == syms.with_stmt\n            and len(n.children) > 2\n            and n.children[1].type == syms.atom\n        ):\n            atom_children = n.children[1].children\n            if (\n                len(atom_children) == 3\n                and atom_children[0].type == token.LPAR\n                and _contains_asexpr(atom_children[1])\n                and atom_children[2].type == token.RPAR\n            ):\n                features.add(Feature.PARENTHESIZED_CONTEXT_MANAGERS)\n\n        elif n.type == syms.match_stmt:\n            features.add(Feature.PATTERN_MATCHING)\n\n        elif n.type in {syms.subscriptlist, syms.trailer} and any(\n            child.type == syms.star_expr for child in n.children\n        ):\n            features.add(Feature.VARIADIC_GENERICS)\n\n        elif (\n            n.type == syms.tname_star\n            and len(n.children) == 3\n            and n.children[2].type == syms.star_expr\n        ):\n            features.add(Feature.VARIADIC_GENERICS)\n\n        elif n.type in (syms.type_stmt, syms.typeparams):\n            features.add(Feature.TYPE_PARAMS)\n\n        elif (\n            n.type in (syms.typevartuple, syms.paramspec, syms.typevar)\n            and n.children[-2].type == token.EQUAL\n        ):\n            features.add(Feature.TYPE_PARAM_DEFAULTS)\n\n        elif (\n            n.type == syms.except_clause\n            and len(n.children) >= 2\n            and (\n                n.children[1].type == token.STAR or n.children[1].type == syms.testlist\n            )\n        ):\n            is_star_except = n.children[1].type == token.STAR\n\n            if is_star_except:\n                features.add(Feature.EXCEPT_STAR)\n\n            # Presence of except* pushes as clause 1 index back\n            has_as_clause = (\n                len(n.children) >= is_star_except + 3\n                and n.children[is_star_except + 2].type == token.NAME\n                and n.children[is_star_except + 2].value == \"as\"  # type: ignore\n            )\n\n            # If there's no 'as' clause and the except expression is a testlist.\n            if not has_as_clause and (\n                (is_star_except and n.children[2].type == syms.testlist)\n                or (not is_star_except and n.children[1].type == syms.testlist)\n            ):\n                features.add(Feature.UNPARENTHESIZED_EXCEPT_TYPES)\n\n    return features"
    },
    {
      "path": "src/black/files.py",
      "version": "new",
      "line": 32,
      "kind": "module",
      "qualname": "src.black.files",
      "span": null,
      "reason": "diff_new_line_outside_defs",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": null,
      "old_code": null
    },
    {
      "path": "src/black/linegen.py",
      "version": "new",
      "line": 1475,
      "kind": "function",
      "qualname": "src.black.linegen.normalize_invisible_parens",
      "span": [
        1475,
        1608
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def normalize_invisible_parens(\n    node: Node, parens_after: set[str], *, mode: Mode, features: Collection[Feature]\n) -> None:\n    \"\"\"Make existing optional parentheses invisible or create new ones.\n\n    `parens_after` is a set of string leaf values immediately after which parens\n    should be put.\n\n    Standardizes on visible parentheses for single-element tuples, and keeps\n    existing visible parentheses for other tuples and generator expressions.\n    \"\"\"\n    for pc in list_comments(node.prefix, is_endmarker=False, mode=mode):\n        if pc.value in FMT_OFF:\n            # This `node` has a prefix with `# fmt: off`, don't mess with parens.\n            return\n\n    # The multiple context managers grammar has a different pattern, thus this is\n    # separate from the for-loop below. This possibly wraps them in invisible parens,\n    # and later will be removed in remove_with_parens when needed.\n    if node.type == syms.with_stmt:\n        _maybe_wrap_cms_in_parens(node, mode, features)\n\n    check_lpar = False\n    for index, child in enumerate(list(node.children)):\n        # Fixes a bug where invisible parens are not properly stripped from\n        # assignment statements that contain type annotations.\n        if isinstance(child, Node) and child.type == syms.annassign:\n            normalize_invisible_parens(\n                child, parens_after=parens_after, mode=mode, features=features\n            )\n\n        # Fixes a bug where invisible parens are not properly wrapped around\n        # case blocks.\n        if isinstance(child, Node) and child.type == syms.case_block:\n            normalize_invisible_parens(\n                child, parens_after={\"case\"}, mode=mode, features=features\n            )\n\n        # Add parentheses around if guards in case blocks\n        if isinstance(child, Node) and child.type == syms.guard:\n            normalize_invisible_parens(\n                child, parens_after={\"if\"}, mode=mode, features=features\n            )\n\n        # Add parentheses around long tuple unpacking in assignments.\n        if (\n            index == 0\n            and isinstance(child, Node)\n            and child.type == syms.testlist_star_expr\n        ):\n            check_lpar = True\n\n        # Check for assignment LHS with preview feature enabled\n        if (\n            Preview.remove_parens_from_assignment_lhs in mode\n            and index == 0\n            and isinstance(child, Node)\n            and child.type == syms.atom\n            and node.type == syms.expr_stmt\n            and not _atom_has_magic_trailing_comma(child, mode)\n            and not _is_atom_multiline(child)\n        ):\n            if maybe_make_parens_invisible_in_atom(\n                child,\n                parent=node,\n                mode=mode,\n                features=features,\n                remove_brackets_around_comma=True,\n                allow_star_expr=True,\n            ):\n                wrap_in_parentheses(node, child, visible=False)\n\n        if check_lpar:\n            if (\n                child.type == syms.atom\n                and node.type == syms.for_stmt\n                and isinstance(child.prev_sibling, Leaf)\n                and child.prev_sibling.type == token.NAME\n                and child.prev_sibling.value == \"for\"\n            ):\n                if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    mode=mode,\n                    features=features,\n                    remove_brackets_around_comma=True,\n                ):\n                    wrap_in_parentheses(node, child, visible=False)\n            elif isinstance(child, Node) and node.type == syms.with_stmt:\n                remove_with_parens(child, node, mode=mode, features=features)\n            elif child.type == syms.atom and not (\n                \"in\" in parens_after\n                and len(child.children) == 3\n                and is_lpar_token(child.children[0])\n                and is_rpar_token(child.children[-1])\n                and child.children[1].type == syms.test\n            ):\n                if maybe_make_parens_invisible_in_atom(\n                    child, parent=node, mode=mode, features=features\n                ):\n                    wrap_in_parentheses(node, child, visible=False)\n            elif is_one_tuple(child):\n                wrap_in_parentheses(node, child, visible=True)\n            elif node.type == syms.import_from:\n                _normalize_import_from(node, child, index)\n                break\n            elif (\n                index == 1\n                and child.type == token.STAR\n                and node.type == syms.except_clause\n            ):\n                # In except* (PEP 654), the star is actually part of\n                # of the keyword. So we need to skip the insertion of\n                # invisible parentheses to work more precisely.\n                continue\n\n            elif (\n                isinstance(child, Leaf)\n                and child.next_sibling is not None\n                and child.next_sibling.type == token.COLON\n                and child.value == \"case\"\n            ):\n                # A special patch for \"case case:\" scenario, the second occurrence\n                # of case will be not parsed as a Python keyword.\n                break\n\n            elif not is_multiline_string(child):\n                wrap_in_parentheses(node, child, visible=False)\n\n        comma_check = child.type == token.COMMA\n\n        check_lpar = isinstance(child, Leaf) and (\n            child.value in parens_after or comma_check\n        )",
      "old_code": "def normalize_invisible_parens(  # noqa: C901\n    node: Node, parens_after: set[str], *, mode: Mode, features: Collection[Feature]\n) -> None:\n    \"\"\"Make existing optional parentheses invisible or create new ones.\n\n    `parens_after` is a set of string leaf values immediately after which parens\n    should be put.\n\n    Standardizes on visible parentheses for single-element tuples, and keeps\n    existing visible parentheses for other tuples and generator expressions.\n    \"\"\"\n    for pc in list_comments(node.prefix, is_endmarker=False, mode=mode):\n        if pc.value in FMT_OFF:\n            # This `node` has a prefix with `# fmt: off`, don't mess with parens.\n            return\n\n    # The multiple context managers grammar has a different pattern, thus this is\n    # separate from the for-loop below. This possibly wraps them in invisible parens,\n    # and later will be removed in remove_with_parens when needed.\n    if node.type == syms.with_stmt:\n        _maybe_wrap_cms_in_parens(node, mode, features)\n\n    check_lpar = False\n    for index, child in enumerate(list(node.children)):\n        # Fixes a bug where invisible parens are not properly stripped from\n        # assignment statements that contain type annotations.\n        if isinstance(child, Node) and child.type == syms.annassign:\n            normalize_invisible_parens(\n                child, parens_after=parens_after, mode=mode, features=features\n            )\n\n        # Fixes a bug where invisible parens are not properly wrapped around\n        # case blocks.\n        if isinstance(child, Node) and child.type == syms.case_block:\n            normalize_invisible_parens(\n                child, parens_after={\"case\"}, mode=mode, features=features\n            )\n\n        # Add parentheses around if guards in case blocks\n        if isinstance(child, Node) and child.type == syms.guard:\n            normalize_invisible_parens(\n                child, parens_after={\"if\"}, mode=mode, features=features\n            )\n\n        # Add parentheses around long tuple unpacking in assignments.\n        if (\n            index == 0\n            and isinstance(child, Node)\n            and child.type == syms.testlist_star_expr\n        ):\n            check_lpar = True\n\n        # Check for assignment LHS with preview feature enabled\n        if (\n            Preview.remove_parens_from_assignment_lhs in mode\n            and index == 0\n            and isinstance(child, Node)\n            and child.type == syms.atom\n            and node.type == syms.expr_stmt\n            and not _atom_has_magic_trailing_comma(child, mode)\n            and not _is_atom_multiline(child)\n        ):\n            if maybe_make_parens_invisible_in_atom(\n                child,\n                parent=node,\n                mode=mode,\n                features=features,\n                remove_brackets_around_comma=True,\n                allow_star_expr=True,\n            ):\n                wrap_in_parentheses(node, child, visible=False)\n\n        if check_lpar:\n            if (\n                child.type == syms.atom\n                and node.type == syms.for_stmt\n                and isinstance(child.prev_sibling, Leaf)\n                and child.prev_sibling.type == token.NAME\n                and child.prev_sibling.value == \"for\"\n            ):\n                if maybe_make_parens_invisible_in_atom(\n                    child,\n                    parent=node,\n                    mode=mode,\n                    features=features,\n                    remove_brackets_around_comma=True,\n                ):\n                    wrap_in_parentheses(node, child, visible=False)\n            elif isinstance(child, Node) and node.type == syms.with_stmt:\n                remove_with_parens(child, node, mode=mode, features=features)\n            elif child.type == syms.atom and not (\n                \"in\" in parens_after\n                and len(child.children) == 3\n                and is_lpar_token(child.children[0])\n                and is_rpar_token(child.children[-1])\n                and child.children[1].type == syms.test\n            ):\n                if maybe_make_parens_invisible_in_atom(\n                    child, parent=node, mode=mode, features=features\n                ):\n                    wrap_in_parentheses(node, child, visible=False)\n            elif is_one_tuple(child):\n                wrap_in_parentheses(node, child, visible=True)\n            elif node.type == syms.import_from:\n                _normalize_import_from(node, child, index)\n                break\n            elif (\n                index == 1\n                and child.type == token.STAR\n                and node.type == syms.except_clause\n            ):\n                # In except* (PEP 654), the star is actually part of\n                # of the keyword. So we need to skip the insertion of\n                # invisible parentheses to work more precisely.\n                continue\n\n            elif (\n                isinstance(child, Leaf)\n                and child.next_sibling is not None\n                and child.next_sibling.type == token.COLON\n                and child.value == \"case\"\n            ):\n                # A special patch for \"case case:\" scenario, the second occurrence\n                # of case will be not parsed as a Python keyword.\n                break\n\n            elif not is_multiline_string(child):\n                wrap_in_parentheses(node, child, visible=False)\n\n        comma_check = child.type == token.COMMA\n\n        check_lpar = isinstance(child, Leaf) and (\n            child.value in parens_after or comma_check\n        )"
    },
    {
      "path": "src/black/lines.py",
      "version": "new",
      "line": 619,
      "kind": "function",
      "qualname": "src.black.lines.EmptyLineTracker._maybe_empty_lines",
      "span": [
        619,
        710
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def _maybe_empty_lines(self, current_line: Line) -> tuple[int, int]:\n        max_allowed = 1\n        if current_line.depth == 0:\n            max_allowed = 1 if self.mode.is_pyi else 2\n\n        if current_line.leaves:\n            # Consume the first leaf's extra newlines.\n            first_leaf = current_line.leaves[0]\n            before = first_leaf.prefix.count(\"\\n\")\n            before = min(before, max_allowed)\n            first_leaf.prefix = \"\"\n        else:\n            before = 0\n\n        user_had_newline = bool(before)\n        depth = current_line.depth\n\n        # Mutate self.previous_defs, remainder of this function should be pure\n        previous_def = None\n        while self.previous_defs and self.previous_defs[-1].depth >= depth:\n            previous_def = self.previous_defs.pop()\n        if current_line.is_def or current_line.is_class:\n            self.previous_defs.append(current_line)\n\n        if self.previous_line is None:\n            # Don't insert empty lines before the first line in the file.\n            return 0, 0\n\n        if current_line.is_docstring:\n            if self.previous_line.is_class:\n                return 0, 1\n            if self.previous_line.opens_block and self.previous_line.is_def:\n                return 0, 0\n\n        if previous_def is not None:\n            assert self.previous_line is not None\n            if self.mode.is_pyi:\n                if previous_def.is_class and not previous_def.is_stub_class:\n                    before = 1\n                elif depth and not current_line.is_def and self.previous_line.is_def:\n                    # Empty lines between attributes and methods should be preserved.\n                    before = 1 if user_had_newline else 0\n                elif depth:\n                    before = 0\n                else:\n                    before = 1\n            else:\n                if depth:\n                    before = 1\n                elif (\n                    not depth\n                    and previous_def.depth\n                    and current_line.leaves[-1].type == token.COLON\n                    and (\n                        current_line.leaves[0].value\n                        not in (\"with\", \"try\", \"for\", \"while\", \"if\", \"match\")\n                    )\n                ):\n                    # We shouldn't add two newlines between an indented function and\n                    # a dependent non-indented clause. This is to avoid issues with\n                    # conditional function definitions that are technically top-level\n                    # and therefore get two trailing newlines, but look weird and\n                    # inconsistent when they're followed by elif, else, etc. This is\n                    # worse because these functions only get *one* preceding newline\n                    # already.\n                    before = 1\n                else:\n                    before = 2\n\n        if current_line.is_decorator or current_line.is_def or current_line.is_class:\n            return self._maybe_empty_lines_for_class_or_def(\n                current_line, before, user_had_newline\n            )\n\n        if (\n            self.previous_line.is_import\n            and self.previous_line.depth == 0\n            and current_line.depth == 0\n            and not current_line.is_import\n            and Preview.always_one_newline_after_import in self.mode\n        ):\n            return 1, 0\n\n        if (\n            self.previous_line.is_import\n            and not current_line.is_import\n            and not current_line.is_fmt_pass_converted(first_leaf_matches=is_import)\n            and depth == self.previous_line.depth\n        ):\n            return (before or 1), 0\n\n        return before, 0",
      "old_code": "    def _maybe_empty_lines(self, current_line: Line) -> tuple[int, int]:  # noqa: C901\n        max_allowed = 1\n        if current_line.depth == 0:\n            max_allowed = 1 if self.mode.is_pyi else 2\n\n        if current_line.leaves:\n            # Consume the first leaf's extra newlines.\n            first_leaf = current_line.leaves[0]\n            before = first_leaf.prefix.count(\"\\n\")\n            before = min(before, max_allowed)\n            first_leaf.prefix = \"\"\n        else:\n            before = 0\n\n        user_had_newline = bool(before)\n        depth = current_line.depth\n\n        # Mutate self.previous_defs, remainder of this function should be pure\n        previous_def = None\n        while self.previous_defs and self.previous_defs[-1].depth >= depth:\n            previous_def = self.previous_defs.pop()\n        if current_line.is_def or current_line.is_class:\n            self.previous_defs.append(current_line)\n\n        if self.previous_line is None:\n            # Don't insert empty lines before the first line in the file.\n            return 0, 0\n\n        if current_line.is_docstring:\n            if self.previous_line.is_class:\n                return 0, 1\n            if self.previous_line.opens_block and self.previous_line.is_def:\n                return 0, 0\n\n        if previous_def is not None:\n            assert self.previous_line is not None\n            if self.mode.is_pyi:\n                if previous_def.is_class and not previous_def.is_stub_class:\n                    before = 1\n                elif depth and not current_line.is_def and self.previous_line.is_def:\n                    # Empty lines between attributes and methods should be preserved.\n                    before = 1 if user_had_newline else 0\n                elif depth:\n                    before = 0\n                else:\n                    before = 1\n            else:\n                if depth:\n                    before = 1\n                elif (\n                    not depth\n                    and previous_def.depth\n                    and current_line.leaves[-1].type == token.COLON\n                    and (\n                        current_line.leaves[0].value\n                        not in (\"with\", \"try\", \"for\", \"while\", \"if\", \"match\")\n                    )\n                ):\n                    # We shouldn't add two newlines between an indented function and\n                    # a dependent non-indented clause. This is to avoid issues with\n                    # conditional function definitions that are technically top-level\n                    # and therefore get two trailing newlines, but look weird and\n                    # inconsistent when they're followed by elif, else, etc. This is\n                    # worse because these functions only get *one* preceding newline\n                    # already.\n                    before = 1\n                else:\n                    before = 2\n\n        if current_line.is_decorator or current_line.is_def or current_line.is_class:\n            return self._maybe_empty_lines_for_class_or_def(\n                current_line, before, user_had_newline\n            )\n\n        if (\n            self.previous_line.is_import\n            and self.previous_line.depth == 0\n            and current_line.depth == 0\n            and not current_line.is_import\n            and Preview.always_one_newline_after_import in self.mode\n        ):\n            return 1, 0\n\n        if (\n            self.previous_line.is_import\n            and not current_line.is_import\n            and not current_line.is_fmt_pass_converted(first_leaf_matches=is_import)\n            and depth == self.previous_line.depth\n        ):\n            return (before or 1), 0\n\n        return before, 0"
    },
    {
      "path": "src/black/lines.py",
      "version": "new",
      "line": 712,
      "kind": "function",
      "qualname": "src.black.lines.EmptyLineTracker._maybe_empty_lines_for_class_or_def",
      "span": [
        712,
        790
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "    def _maybe_empty_lines_for_class_or_def(\n        self, current_line: Line, before: int, user_had_newline: bool\n    ) -> tuple[int, int]:\n        assert self.previous_line is not None\n\n        if self.previous_line.is_decorator:\n            if self.mode.is_pyi and current_line.is_stub_class:\n                # Insert an empty line after a decorated stub class\n                return 0, 1\n            return 0, 0\n\n        if self.previous_line.depth < current_line.depth and (\n            self.previous_line.is_class or self.previous_line.is_def\n        ):\n            if self.mode.is_pyi:\n                return 0, 0\n            return 1 if user_had_newline else 0, 0\n\n        comment_to_add_newlines: LinesBlock | None = None\n        if (\n            self.previous_line.is_comment\n            and self.previous_line.depth == current_line.depth\n            and before == 0\n        ):\n            slc = self.semantic_leading_comment\n            if (\n                slc is not None\n                and slc.previous_block is not None\n                and not slc.previous_block.original_line.is_class\n                and not slc.previous_block.original_line.opens_block\n                and slc.before <= 1\n            ):\n                comment_to_add_newlines = slc\n            else:\n                return 0, 0\n\n        if self.mode.is_pyi:\n            if current_line.is_class or self.previous_line.is_class:\n                if self.previous_line.depth < current_line.depth:\n                    newlines = 0\n                elif self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_stub_class and self.previous_line.is_stub_class:\n                    # No blank line between classes with an empty body\n                    newlines = 0\n                else:\n                    newlines = 1\n            # Don't inspect the previous line if it's part of the body of the previous\n            # statement in the same level, we always want a blank line if there's\n            # something with a body preceding.\n            elif self.previous_line.depth > current_line.depth:\n                newlines = 1\n            elif (\n                current_line.is_def or current_line.is_decorator\n            ) and not self.previous_line.is_def:\n                if current_line.depth:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved.\n                    newlines = min(1, before)\n                else:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n            else:\n                newlines = 0\n        else:\n            newlines = 1 if current_line.depth else 2\n            # If a user has left no space after a dummy implementation, don't insert\n            # new lines. This is useful for instance for @overload or Protocols.\n            if self.previous_line.is_stub_def and not user_had_newline:\n                newlines = 0\n        if comment_to_add_newlines is not None:\n            previous_block = comment_to_add_newlines.previous_block\n            if previous_block is not None:\n                comment_to_add_newlines.before = (\n                    max(comment_to_add_newlines.before, newlines) - previous_block.after\n                )\n                newlines = 0\n        return newlines, 0",
      "old_code": "    def _maybe_empty_lines_for_class_or_def(  # noqa: C901\n        self, current_line: Line, before: int, user_had_newline: bool\n    ) -> tuple[int, int]:\n        assert self.previous_line is not None\n\n        if self.previous_line.is_decorator:\n            if self.mode.is_pyi and current_line.is_stub_class:\n                # Insert an empty line after a decorated stub class\n                return 0, 1\n            return 0, 0\n\n        if self.previous_line.depth < current_line.depth and (\n            self.previous_line.is_class or self.previous_line.is_def\n        ):\n            if self.mode.is_pyi:\n                return 0, 0\n            return 1 if user_had_newline else 0, 0\n\n        comment_to_add_newlines: LinesBlock | None = None\n        if (\n            self.previous_line.is_comment\n            and self.previous_line.depth == current_line.depth\n            and before == 0\n        ):\n            slc = self.semantic_leading_comment\n            if (\n                slc is not None\n                and slc.previous_block is not None\n                and not slc.previous_block.original_line.is_class\n                and not slc.previous_block.original_line.opens_block\n                and slc.before <= 1\n            ):\n                comment_to_add_newlines = slc\n            else:\n                return 0, 0\n\n        if self.mode.is_pyi:\n            if current_line.is_class or self.previous_line.is_class:\n                if self.previous_line.depth < current_line.depth:\n                    newlines = 0\n                elif self.previous_line.depth > current_line.depth:\n                    newlines = 1\n                elif current_line.is_stub_class and self.previous_line.is_stub_class:\n                    # No blank line between classes with an empty body\n                    newlines = 0\n                else:\n                    newlines = 1\n            # Don't inspect the previous line if it's part of the body of the previous\n            # statement in the same level, we always want a blank line if there's\n            # something with a body preceding.\n            elif self.previous_line.depth > current_line.depth:\n                newlines = 1\n            elif (\n                current_line.is_def or current_line.is_decorator\n            ) and not self.previous_line.is_def:\n                if current_line.depth:\n                    # In classes empty lines between attributes and methods should\n                    # be preserved.\n                    newlines = min(1, before)\n                else:\n                    # Blank line between a block of functions (maybe with preceding\n                    # decorators) and a block of non-functions\n                    newlines = 1\n            else:\n                newlines = 0\n        else:\n            newlines = 1 if current_line.depth else 2\n            # If a user has left no space after a dummy implementation, don't insert\n            # new lines. This is useful for instance for @overload or Protocols.\n            if self.previous_line.is_stub_def and not user_had_newline:\n                newlines = 0\n        if comment_to_add_newlines is not None:\n            previous_block = comment_to_add_newlines.previous_block\n            if previous_block is not None:\n                comment_to_add_newlines.before = (\n                    max(comment_to_add_newlines.before, newlines) - previous_block.after\n                )\n                newlines = 0\n        return newlines, 0"
    },
    {
      "path": "src/black/lines.py",
      "version": "new",
      "line": 825,
      "kind": "function",
      "qualname": "src.black.lines.is_line_short_enough",
      "span": [
        825,
        917
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def is_line_short_enough(line: Line, *, mode: Mode, line_str: str = \"\") -> bool:\n    \"\"\"For non-multiline strings, return True if `line` is no longer than `line_length`.\n    For multiline strings, looks at the context around `line` to determine\n    if it should be inlined or split up.\n    Uses the provided `line_str` rendering, if any, otherwise computes a new one.\n    \"\"\"\n    if not line_str:\n        line_str = line_to_string(line)\n\n    if Preview.multiline_string_handling not in mode:\n        return (\n            str_width(line_str) <= mode.line_length\n            and \"\\n\" not in line_str  # multiline strings\n            and not line.contains_standalone_comments()\n        )\n\n    if line.contains_standalone_comments():\n        return False\n    if \"\\n\" not in line_str:\n        # No multiline strings (MLS) present\n        return str_width(line_str) <= mode.line_length\n\n    first, *_, last = line_str.split(\"\\n\")\n    if str_width(first) > mode.line_length or str_width(last) > mode.line_length:\n        return False\n\n    # Traverse the AST to examine the context of the multiline string (MLS),\n    # tracking aspects such as depth and comma existence,\n    # to determine whether to split the MLS or keep it together.\n    # Depth (which is based on the existing bracket_depth concept)\n    # is needed to determine nesting level of the MLS.\n    # Includes special case for trailing commas.\n    commas: list[int] = []  # tracks number of commas per depth level\n    multiline_string: Leaf | None = None\n    # store the leaves that contain parts of the MLS\n    multiline_string_contexts: list[LN] = []\n\n    max_level_to_update: int | float = math.inf  # track the depth of the MLS\n    for i, leaf in enumerate(line.leaves):\n        if max_level_to_update == math.inf:\n            had_comma: int | None = None\n            if leaf.bracket_depth + 1 > len(commas):\n                commas.append(0)\n            elif leaf.bracket_depth + 1 < len(commas):\n                had_comma = commas.pop()\n            if (\n                had_comma is not None\n                and multiline_string is not None\n                and multiline_string.bracket_depth == leaf.bracket_depth + 1\n            ):\n                # Have left the level with the MLS, stop tracking commas\n                max_level_to_update = leaf.bracket_depth\n                if had_comma > 0:\n                    # MLS was in parens with at least one comma - force split\n                    return False\n\n        if leaf.bracket_depth <= max_level_to_update and leaf.type == token.COMMA:\n            # Inside brackets, ignore trailing comma\n            # directly after MLS/MLS-containing expression\n            ignore_ctxs: list[LN | None] = [None]\n            ignore_ctxs += multiline_string_contexts\n            if (line.inside_brackets or leaf.bracket_depth > 0) and (\n                i != len(line.leaves) - 1 or leaf.prev_sibling not in ignore_ctxs\n            ):\n                commas[leaf.bracket_depth] += 1\n        if max_level_to_update != math.inf:\n            max_level_to_update = min(max_level_to_update, leaf.bracket_depth)\n\n        if is_multiline_string(leaf):\n            if leaf.parent and (\n                leaf.parent.type == syms.test\n                or (leaf.parent.parent and leaf.parent.parent.type == syms.dictsetmaker)\n            ):\n                # Keep ternary and dictionary values parenthesized\n                return False\n            if len(multiline_string_contexts) > 0:\n                # >1 multiline string cannot fit on a single line - force split\n                return False\n            multiline_string = leaf\n            ctx: LN = leaf\n            # fetch the leaf components of the MLS in the AST\n            while str(ctx) in line_str:\n                multiline_string_contexts.append(ctx)\n                if ctx.parent is None:\n                    break\n                ctx = ctx.parent\n\n    # May not have a triple-quoted multiline string at all,\n    # in case of a regular string with embedded newlines and line continuations\n    if len(multiline_string_contexts) == 0:\n        return True\n\n    return all(val == 0 for val in commas)",
      "old_code": "def is_line_short_enough(  # noqa: C901\n    line: Line, *, mode: Mode, line_str: str = \"\"\n) -> bool:\n    \"\"\"For non-multiline strings, return True if `line` is no longer than `line_length`.\n    For multiline strings, looks at the context around `line` to determine\n    if it should be inlined or split up.\n    Uses the provided `line_str` rendering, if any, otherwise computes a new one.\n    \"\"\"\n    if not line_str:\n        line_str = line_to_string(line)\n\n    if Preview.multiline_string_handling not in mode:\n        return (\n            str_width(line_str) <= mode.line_length\n            and \"\\n\" not in line_str  # multiline strings\n            and not line.contains_standalone_comments()\n        )\n\n    if line.contains_standalone_comments():\n        return False\n    if \"\\n\" not in line_str:\n        # No multiline strings (MLS) present\n        return str_width(line_str) <= mode.line_length\n\n    first, *_, last = line_str.split(\"\\n\")\n    if str_width(first) > mode.line_length or str_width(last) > mode.line_length:\n        return False\n\n    # Traverse the AST to examine the context of the multiline string (MLS),\n    # tracking aspects such as depth and comma existence,\n    # to determine whether to split the MLS or keep it together.\n    # Depth (which is based on the existing bracket_depth concept)\n    # is needed to determine nesting level of the MLS.\n    # Includes special case for trailing commas.\n    commas: list[int] = []  # tracks number of commas per depth level\n    multiline_string: Leaf | None = None\n    # store the leaves that contain parts of the MLS\n    multiline_string_contexts: list[LN] = []\n\n    max_level_to_update: int | float = math.inf  # track the depth of the MLS\n    for i, leaf in enumerate(line.leaves):\n        if max_level_to_update == math.inf:\n            had_comma: int | None = None\n            if leaf.bracket_depth + 1 > len(commas):\n                commas.append(0)\n            elif leaf.bracket_depth + 1 < len(commas):\n                had_comma = commas.pop()\n            if (\n                had_comma is not None\n                and multiline_string is not None\n                and multiline_string.bracket_depth == leaf.bracket_depth + 1\n            ):\n                # Have left the level with the MLS, stop tracking commas\n                max_level_to_update = leaf.bracket_depth\n                if had_comma > 0:\n                    # MLS was in parens with at least one comma - force split\n                    return False\n\n        if leaf.bracket_depth <= max_level_to_update and leaf.type == token.COMMA:\n            # Inside brackets, ignore trailing comma\n            # directly after MLS/MLS-containing expression\n            ignore_ctxs: list[LN | None] = [None]\n            ignore_ctxs += multiline_string_contexts\n            if (line.inside_brackets or leaf.bracket_depth > 0) and (\n                i != len(line.leaves) - 1 or leaf.prev_sibling not in ignore_ctxs\n            ):\n                commas[leaf.bracket_depth] += 1\n        if max_level_to_update != math.inf:\n            max_level_to_update = min(max_level_to_update, leaf.bracket_depth)\n\n        if is_multiline_string(leaf):\n            if leaf.parent and (\n                leaf.parent.type == syms.test\n                or (leaf.parent.parent and leaf.parent.parent.type == syms.dictsetmaker)\n            ):\n                # Keep ternary and dictionary values parenthesized\n                return False\n            if len(multiline_string_contexts) > 0:\n                # >1 multiline string cannot fit on a single line - force split\n                return False\n            multiline_string = leaf\n            ctx: LN = leaf\n            # fetch the leaf components of the MLS in the AST\n            while str(ctx) in line_str:\n                multiline_string_contexts.append(ctx)\n                if ctx.parent is None:\n                    break\n                ctx = ctx.parent\n\n    # May not have a triple-quoted multiline string at all,\n    # in case of a regular string with embedded newlines and line continuations\n    if len(multiline_string_contexts) == 0:\n        return True\n\n    return all(val == 0 for val in commas)"
    },
    {
      "path": "src/black/nodes.py",
      "version": "new",
      "line": 180,
      "kind": "function",
      "qualname": "src.black.nodes.whitespace",
      "span": [
        180,
        419
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def whitespace(leaf: Leaf, *, complex_subscript: bool, mode: Mode) -> str:\n    \"\"\"Return whitespace prefix if needed for the given `leaf`.\n\n    `complex_subscript` signals whether the given leaf is part of a subscription\n    which has non-trivial arguments, like arithmetic expressions or function calls.\n    \"\"\"\n    NO: Final[str] = \"\"\n    SPACE: Final[str] = \" \"\n    DOUBLESPACE: Final[str] = \"  \"\n    t = leaf.type\n    p = leaf.parent\n    v = leaf.value\n    if t in ALWAYS_NO_SPACE:\n        return NO\n\n    if t == token.COMMENT:\n        return DOUBLESPACE\n\n    assert p is not None, f\"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}\"\n    if t == token.COLON and p.type not in {\n        syms.subscript,\n        syms.subscriptlist,\n        syms.sliceop,\n    }:\n        return NO\n\n    if t == token.LBRACE and p.type in (\n        syms.fstring_replacement_field,\n        syms.tstring_replacement_field,\n    ):\n        return NO\n\n    prev = leaf.prev_sibling\n    if not prev:\n        prevp = preceding_leaf(p)\n        if not prevp or prevp.type in OPENING_BRACKETS:\n            return NO\n\n        if t == token.COLON:\n            if prevp.type == token.COLON:\n                return NO\n\n            elif prevp.type != token.COMMA and not complex_subscript:\n                return NO\n\n            return SPACE\n\n        if prevp.type == token.EQUAL:\n            if prevp.parent:\n                if prevp.parent.type in {\n                    syms.arglist,\n                    syms.argument,\n                    syms.parameters,\n                    syms.varargslist,\n                }:\n                    return NO\n\n                elif prevp.parent.type == syms.typedargslist:\n                    # A bit hacky: if the equal sign has whitespace, it means we\n                    # previously found it's a typed argument.  So, we're using\n                    # that, too.\n                    return prevp.prefix\n\n        elif (\n            prevp.type == token.STAR\n            and parent_type(prevp) == syms.star_expr\n            and parent_type(prevp.parent) in (syms.subscriptlist, syms.tname_star)\n        ):\n            # No space between typevar tuples or unpacking them.\n            return NO\n\n        elif prevp.type in VARARGS_SPECIALS:\n            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):\n                return NO\n\n        elif prevp.type == token.COLON:\n            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:\n                return SPACE if complex_subscript else NO\n\n        elif (\n            prevp.parent\n            and prevp.parent.type == syms.factor\n            and prevp.type in MATH_OPERATORS\n        ):\n            return NO\n\n        elif prevp.type == token.AT and p.parent and p.parent.type == syms.decorator:\n            # no space in decorators\n            return NO\n\n    elif prev.type in OPENING_BRACKETS:\n        return NO\n\n    elif prev.type == token.BANG:\n        return NO\n\n    if p.type in {syms.parameters, syms.arglist}:\n        # untyped function signatures or calls\n        if not prev or prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.varargslist:\n        # lambdas\n        if prev and prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.typedargslist:\n        # typed function signatures\n        if not prev:\n            return NO\n\n        if t == token.EQUAL:\n            if prev.type not in TYPED_NAMES:\n                return NO\n\n        elif prev.type == token.EQUAL:\n            # A bit hacky: if the equal sign has whitespace, it means we\n            # previously found it's a typed argument.  So, we're using that, too.\n            return prev.prefix\n\n        elif prev.type != token.COMMA:\n            return NO\n\n    elif p.type in TYPED_NAMES:\n        # type names\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type != token.COMMA:\n                return NO\n\n    elif p.type == syms.trailer:\n        # attributes and calls\n        if t == token.LPAR or t == token.RPAR:\n            return NO\n\n        if not prev:\n            if t == token.DOT or t == token.LSQB:\n                return NO\n\n        elif prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.argument:\n        # single argument\n        if t == token.EQUAL:\n            return NO\n\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type == token.LPAR:\n                return NO\n\n        elif prev.type in {token.EQUAL} | VARARGS_SPECIALS:\n            return NO\n\n    elif p.type == syms.decorator:\n        # decorators\n        return NO\n\n    elif p.type == syms.dotted_name:\n        if prev:\n            return NO\n\n        prevp = preceding_leaf(p)\n        if not prevp or prevp.type == token.AT or prevp.type == token.DOT:\n            return NO\n\n    elif p.type == syms.classdef:\n        if t == token.LPAR:\n            return NO\n\n        if prev and prev.type == token.LPAR:\n            return NO\n\n    elif p.type in {syms.subscript, syms.sliceop}:\n        # indexing\n        if not prev:\n            assert p.parent is not None, \"subscripts are always parented\"\n            if p.parent.type == syms.subscriptlist:\n                return SPACE\n\n            return NO\n\n        elif t == token.COLONEQUAL or prev.type == token.COLONEQUAL:\n            return SPACE\n\n        elif not complex_subscript:\n            return NO\n\n    elif p.type == syms.atom:\n        if prev and t == token.DOT:\n            # dots, but not the first one.\n            return NO\n\n    elif p.type == syms.dictsetmaker:\n        # dict unpacking\n        if prev and prev.type == token.DOUBLESTAR:\n            return NO\n\n    elif p.type in {syms.factor, syms.star_expr}:\n        # unary ops\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type in OPENING_BRACKETS:\n                return NO\n\n            prevp_parent = prevp.parent\n            assert prevp_parent is not None\n            if prevp.type == token.COLON and prevp_parent.type in {\n                syms.subscript,\n                syms.sliceop,\n            }:\n                return NO\n\n            elif prevp.type == token.EQUAL and prevp_parent.type == syms.argument:\n                return NO\n\n        elif t in {token.NAME, token.NUMBER, token.STRING}:\n            return NO\n\n    elif p.type == syms.import_from:\n        if t == token.DOT:\n            if prev and prev.type == token.DOT:\n                return NO\n\n        elif t == token.NAME:\n            if v == \"import\":\n                return SPACE\n\n            if prev and prev.type == token.DOT:\n                return NO\n\n    elif p.type == syms.sliceop:\n        return NO\n\n    elif p.type == syms.except_clause:\n        if t == token.STAR:\n            return NO\n\n    return SPACE",
      "old_code": "def whitespace(leaf: Leaf, *, complex_subscript: bool, mode: Mode) -> str:  # noqa: C901\n    \"\"\"Return whitespace prefix if needed for the given `leaf`.\n\n    `complex_subscript` signals whether the given leaf is part of a subscription\n    which has non-trivial arguments, like arithmetic expressions or function calls.\n    \"\"\"\n    NO: Final[str] = \"\"\n    SPACE: Final[str] = \" \"\n    DOUBLESPACE: Final[str] = \"  \"\n    t = leaf.type\n    p = leaf.parent\n    v = leaf.value\n    if t in ALWAYS_NO_SPACE:\n        return NO\n\n    if t == token.COMMENT:\n        return DOUBLESPACE\n\n    assert p is not None, f\"INTERNAL ERROR: hand-made leaf without parent: {leaf!r}\"\n    if t == token.COLON and p.type not in {\n        syms.subscript,\n        syms.subscriptlist,\n        syms.sliceop,\n    }:\n        return NO\n\n    if t == token.LBRACE and p.type in (\n        syms.fstring_replacement_field,\n        syms.tstring_replacement_field,\n    ):\n        return NO\n\n    prev = leaf.prev_sibling\n    if not prev:\n        prevp = preceding_leaf(p)\n        if not prevp or prevp.type in OPENING_BRACKETS:\n            return NO\n\n        if t == token.COLON:\n            if prevp.type == token.COLON:\n                return NO\n\n            elif prevp.type != token.COMMA and not complex_subscript:\n                return NO\n\n            return SPACE\n\n        if prevp.type == token.EQUAL:\n            if prevp.parent:\n                if prevp.parent.type in {\n                    syms.arglist,\n                    syms.argument,\n                    syms.parameters,\n                    syms.varargslist,\n                }:\n                    return NO\n\n                elif prevp.parent.type == syms.typedargslist:\n                    # A bit hacky: if the equal sign has whitespace, it means we\n                    # previously found it's a typed argument.  So, we're using\n                    # that, too.\n                    return prevp.prefix\n\n        elif (\n            prevp.type == token.STAR\n            and parent_type(prevp) == syms.star_expr\n            and parent_type(prevp.parent) in (syms.subscriptlist, syms.tname_star)\n        ):\n            # No space between typevar tuples or unpacking them.\n            return NO\n\n        elif prevp.type in VARARGS_SPECIALS:\n            if is_vararg(prevp, within=VARARGS_PARENTS | UNPACKING_PARENTS):\n                return NO\n\n        elif prevp.type == token.COLON:\n            if prevp.parent and prevp.parent.type in {syms.subscript, syms.sliceop}:\n                return SPACE if complex_subscript else NO\n\n        elif (\n            prevp.parent\n            and prevp.parent.type == syms.factor\n            and prevp.type in MATH_OPERATORS\n        ):\n            return NO\n\n        elif prevp.type == token.AT and p.parent and p.parent.type == syms.decorator:\n            # no space in decorators\n            return NO\n\n    elif prev.type in OPENING_BRACKETS:\n        return NO\n\n    elif prev.type == token.BANG:\n        return NO\n\n    if p.type in {syms.parameters, syms.arglist}:\n        # untyped function signatures or calls\n        if not prev or prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.varargslist:\n        # lambdas\n        if prev and prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.typedargslist:\n        # typed function signatures\n        if not prev:\n            return NO\n\n        if t == token.EQUAL:\n            if prev.type not in TYPED_NAMES:\n                return NO\n\n        elif prev.type == token.EQUAL:\n            # A bit hacky: if the equal sign has whitespace, it means we\n            # previously found it's a typed argument.  So, we're using that, too.\n            return prev.prefix\n\n        elif prev.type != token.COMMA:\n            return NO\n\n    elif p.type in TYPED_NAMES:\n        # type names\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type != token.COMMA:\n                return NO\n\n    elif p.type == syms.trailer:\n        # attributes and calls\n        if t == token.LPAR or t == token.RPAR:\n            return NO\n\n        if not prev:\n            if t == token.DOT or t == token.LSQB:\n                return NO\n\n        elif prev.type != token.COMMA:\n            return NO\n\n    elif p.type == syms.argument:\n        # single argument\n        if t == token.EQUAL:\n            return NO\n\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type == token.LPAR:\n                return NO\n\n        elif prev.type in {token.EQUAL} | VARARGS_SPECIALS:\n            return NO\n\n    elif p.type == syms.decorator:\n        # decorators\n        return NO\n\n    elif p.type == syms.dotted_name:\n        if prev:\n            return NO\n\n        prevp = preceding_leaf(p)\n        if not prevp or prevp.type == token.AT or prevp.type == token.DOT:\n            return NO\n\n    elif p.type == syms.classdef:\n        if t == token.LPAR:\n            return NO\n\n        if prev and prev.type == token.LPAR:\n            return NO\n\n    elif p.type in {syms.subscript, syms.sliceop}:\n        # indexing\n        if not prev:\n            assert p.parent is not None, \"subscripts are always parented\"\n            if p.parent.type == syms.subscriptlist:\n                return SPACE\n\n            return NO\n\n        elif t == token.COLONEQUAL or prev.type == token.COLONEQUAL:\n            return SPACE\n\n        elif not complex_subscript:\n            return NO\n\n    elif p.type == syms.atom:\n        if prev and t == token.DOT:\n            # dots, but not the first one.\n            return NO\n\n    elif p.type == syms.dictsetmaker:\n        # dict unpacking\n        if prev and prev.type == token.DOUBLESTAR:\n            return NO\n\n    elif p.type in {syms.factor, syms.star_expr}:\n        # unary ops\n        if not prev:\n            prevp = preceding_leaf(p)\n            if not prevp or prevp.type in OPENING_BRACKETS:\n                return NO\n\n            prevp_parent = prevp.parent\n            assert prevp_parent is not None\n            if prevp.type == token.COLON and prevp_parent.type in {\n                syms.subscript,\n                syms.sliceop,\n            }:\n                return NO\n\n            elif prevp.type == token.EQUAL and prevp_parent.type == syms.argument:\n                return NO\n\n        elif t in {token.NAME, token.NUMBER, token.STRING}:\n            return NO\n\n    elif p.type == syms.import_from:\n        if t == token.DOT:\n            if prev and prev.type == token.DOT:\n                return NO\n\n        elif t == token.NAME:\n            if v == \"import\":\n                return SPACE\n\n            if prev and prev.type == token.DOT:\n                return NO\n\n    elif p.type == syms.sliceop:\n        return NO\n\n    elif p.type == syms.except_clause:\n        if t == token.STAR:\n            return NO\n\n    return SPACE"
    },
    {
      "path": "src/black/parsing.py",
      "version": "new",
      "line": 195,
      "kind": "function",
      "qualname": "src.black.parsing._stringify_ast",
      "span": [
        182,
        252
      ],
      "reason": "diff_new_line_in_def",
      "is_test": false,
      "seed_type": "code_change",
      "new_code": "def _stringify_ast(node: ast.AST, parent_stack: list[ast.AST]) -> Iterator[str]:\n    if (\n        isinstance(node, ast.Constant)\n        and isinstance(node.value, str)\n        and node.kind == \"u\"\n    ):\n        # It's a quirk of history that we strip the u prefix over here. We used to\n        # rewrite the AST nodes for Python version compatibility and we never copied\n        # over the kind\n        node.kind = None\n\n    yield f\"{'    ' * len(parent_stack)}{node.__class__.__name__}(\"\n\n    for field in sorted(node._fields):\n        # TypeIgnore has only one field 'lineno' which breaks this comparison\n        if isinstance(node, ast.TypeIgnore):\n            break\n\n        try:\n            value: object = getattr(node, field)\n        except AttributeError:\n            continue\n\n        yield f\"{'    ' * (len(parent_stack) + 1)}{field}=\"\n\n        if isinstance(value, list):\n            for item in value:\n                # Ignore nested tuples within del statements, because we may insert\n                # parentheses and they change the AST.\n                if (\n                    field == \"targets\"\n                    and isinstance(node, ast.Delete)\n                    and isinstance(item, ast.Tuple)\n                ):\n                    for elt in _unwrap_tuples(item):\n                        yield from _stringify_ast_with_new_parent(\n                            elt, parent_stack, node\n                        )\n\n                elif isinstance(item, ast.AST):\n                    yield from _stringify_ast_with_new_parent(item, parent_stack, node)\n\n        elif isinstance(value, ast.AST):\n            yield from _stringify_ast_with_new_parent(value, parent_stack, node)\n\n        else:\n            normalized: object\n            if (\n                isinstance(node, ast.Constant)\n                and field == \"value\"\n                and isinstance(value, str)\n                and len(parent_stack) >= 2\n                # Any standalone string, ideally this would\n                # exactly match black.nodes.is_docstring\n                and isinstance(parent_stack[-1], ast.Expr)\n            ):\n                # Constant strings may be indented across newlines, if they are\n                # docstrings; fold spaces after newlines when comparing. Similarly,\n                # trailing and leading space may be removed.\n                normalized = _normalize(\"\\n\", value)\n            elif field == \"type_comment\" and isinstance(value, str):\n                # Trailing whitespace in type comments is removed.\n                normalized = value.rstrip()\n            else:\n                normalized = value\n            yield (\n                f\"{'    ' * (len(parent_stack) + 1)}{normalized!r},  #\"\n                f\" {value.__class__.__name__}\"\n            )\n\n    yield f\"{'    ' * len(parent_stack)})  # /{node.__class__.__name__}\"",
      "old_code": "def _stringify_ast(node: ast.AST, parent_stack: list[ast.AST]) -> Iterator[str]:\n    if (\n        isinstance(node, ast.Constant)\n        and isinstance(node.value, str)\n        and node.kind == \"u\"\n    ):\n        # It's a quirk of history that we strip the u prefix over here. We used to\n        # rewrite the AST nodes for Python version compatibility and we never copied\n        # over the kind\n        node.kind = None\n\n    yield f\"{'    ' * len(parent_stack)}{node.__class__.__name__}(\"\n\n    for field in sorted(node._fields):  # noqa: F402\n        # TypeIgnore has only one field 'lineno' which breaks this comparison\n        if isinstance(node, ast.TypeIgnore):\n            break\n\n        try:\n            value: object = getattr(node, field)\n        except AttributeError:\n            continue\n\n        yield f\"{'    ' * (len(parent_stack) + 1)}{field}=\"\n\n        if isinstance(value, list):\n            for item in value:\n                # Ignore nested tuples within del statements, because we may insert\n                # parentheses and they change the AST.\n                if (\n                    field == \"targets\"\n                    and isinstance(node, ast.Delete)\n                    and isinstance(item, ast.Tuple)\n                ):\n                    for elt in _unwrap_tuples(item):\n                        yield from _stringify_ast_with_new_parent(\n                            elt, parent_stack, node\n                        )\n\n                elif isinstance(item, ast.AST):\n                    yield from _stringify_ast_with_new_parent(item, parent_stack, node)\n\n        elif isinstance(value, ast.AST):\n            yield from _stringify_ast_with_new_parent(value, parent_stack, node)\n\n        else:\n            normalized: object\n            if (\n                isinstance(node, ast.Constant)\n                and field == \"value\"\n                and isinstance(value, str)\n                and len(parent_stack) >= 2\n                # Any standalone string, ideally this would\n                # exactly match black.nodes.is_docstring\n                and isinstance(parent_stack[-1], ast.Expr)\n            ):\n                # Constant strings may be indented across newlines, if they are\n                # docstrings; fold spaces after newlines when comparing. Similarly,\n                # trailing and leading space may be removed.\n                normalized = _normalize(\"\\n\", value)\n            elif field == \"type_comment\" and isinstance(value, str):\n                # Trailing whitespace in type comments is removed.\n                normalized = value.rstrip()\n            else:\n                normalized = value\n            yield (\n                f\"{'    ' * (len(parent_stack) + 1)}{normalized!r},  #\"\n                f\" {value.__class__.__name__}\"\n            )\n\n    yield f\"{'    ' * len(parent_stack)})  # /{node.__class__.__name__}\""
    }
  ],
  "generated_at": "2026-02-10T14:22:43"
}