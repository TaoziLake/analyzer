--- a/src/blib2to3/pgen2/tokenize.py
+++ b/src/blib2to3/pgen2/tokenize.py
@@ -211,6 +211,15 @@
 def printtoken(
     type: int, token: str, srow_col: Coord, erow_col: Coord, line: str
 ) -> None:  # for testing
+    """TODO: docstring
+
+    Args:
+        type:
+        token:
+        srow_col:
+        erow_col:
+        line:
+    """
     srow, scol = srow_col
     erow, ecol = erow_col
     print(f"{srow},{scol}-{erow},{ecol}:\t{tok_name[type]}\t{token!r}")

--- a/src/black/linegen.py
+++ b/src/black/linegen.py
@@ -243,6 +243,11 @@
         node.children[1].prefix = ""
 
     def visit_dictsetmaker(self, node: Node) -> Iterator[Line]:
+        """TODO: docstring
+
+        Args:
+            node:
+        """
         if Preview.wrap_long_dict_values_in_parens in self.mode:
             for i, child in enumerate(node.children):
                 if i == 0:
@@ -643,6 +648,11 @@
         # yield from self.visit_default(node)
 
     def visit_comp_for(self, node: Node) -> Iterator[Line]:
+        """TODO: docstring
+
+        Args:
+            node:
+        """
         if Preview.wrap_comprehension_in in self.mode:
             normalize_invisible_parens(
                 node, parens_after={"in"}, mode=self.mode, features=self.features
@@ -1611,6 +1621,13 @@
 def _normalize_import_from(parent: Node, child: LN, index: int) -> None:
     # "import from" nodes store parentheses directly as part of
     # the statement
+    """TODO: docstring
+
+    Args:
+        parent:
+        child:
+        index:
+    """
     if is_lpar_token(child):
         assert is_rpar_token(parent.children[-1])
         # make parentheses invisible
@@ -1623,6 +1640,13 @@
 
 
 def remove_await_parens(node: Node, mode: Mode, features: Collection[Feature]) -> None:
+    """TODO: docstring
+
+    Args:
+        node:
+        mode:
+        features:
+    """
     if node.children[0].type == token.AWAIT and len(node.children) > 1:
         if (
             node.children[1].type == syms.atom
